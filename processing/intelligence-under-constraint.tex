\documentclass[11pt,letterpaper]{article}

% --------------------------------------------------
% Packages
% --------------------------------------------------

\usepackage{fontspec}
\usepackage{unicode-math}

\setmainfont{Latin Modern Roman}

\setmathfont{Latin Modern Math}

% ================================
% Page layout and spacing
% ================================

\usepackage{geometry}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{setspace}
\usepackage{csquotes}
\usepackage{hyperref}

% --------------------------------------------------
% Page layout
% --------------------------------------------------
\geometry{margin=1in}
\setstretch{1.15}

\usepackage[
  backend=biber,
  style=authoryear,
  sorting=nyt,
  maxcitenames=2,
  maxbibnames=99
]{biblatex}

\addbibresource{intelligence-under-constraint.bib}

% --------------------------------------------------
% Theorem environments
% --------------------------------------------------
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\theoremstyle{plain}
\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]

\theoremstyle{remark}
\newtheorem{remark}{Remark}[section]

% --------------------------------------------------
% Title
% --------------------------------------------------
\title{Intelligence Under Constraint:\\
Construction, Legibility, and Boundary Conditions}
\author{Flyxion}
\date{\today}

\begin{document}
\maketitle

% --------------------------------------------------
% Abstract
% --------------------------------------------------
\begin{abstract}
Contemporary discussions of intelligence, both biological and artificial, are dominated by performance metrics, representational models, and optimization-based framings. These approaches obscure a more fundamental question: what structural conditions must remain invariant for intelligence to persist, generalize, and survive exposure under reuse?  

This essay develops a constraint-first account of intelligence grounded in construction history, invariant-preserving abstraction, modularity, and refusal. Intelligence is treated not as a static capacity or a bundle of skills, but as a mode of regulated interaction with an environment, mediated by semi-permeable boundaries. Drawing on biological membranes, cortical synchronization, evolutionary redundancy, operating system privilege separation, and formal mathematical structure, the essay argues that mature intelligence necessarily regulates its own legibility.  

On this view, refusal is not an ethical afterthought but a constitutive operation; abstraction is compression under lawful transformation; and responsible publication requires effort-gated legibility rather than secrecy or unrestricted openness. The form of the argument enacts these claims by requiring cumulative discipline rather than extractable instruction.
\end{abstract}

% --------------------------------------------------
\section{Introduction}
% --------------------------------------------------

There is a persistent expectation, in both technical and public discourse, that intelligence should be immediately legible. Explanations should be compressible, systems should be reproducible, and ideas should be deployable without extended reconstruction. Within artificial intelligence research, this expectation appears as benchmark-driven evaluation, architectural recipes, and the presumption that progress consists primarily in scaling or optimization. In broader intellectual culture, it appears as demands for accessibility, summarizability, and rapid dissemination.

This essay begins from the claim that this expectation is not neutral. It functions as a selection pressure that privileges shallow correctness, discourages cumulative reasoning, and systematically erodes the very properties that make intelligence general rather than brittle. Ideas that survive such environments do so not because they are structurally robust, but because they are easily paraphrased, weakly constrained, or trivially recontextualized.

The central thesis advanced here is that intelligence is best understood not as a set of capabilities or representations, but as \emph{construction under constraint}. To be intelligent is to build structures over time, to reuse them lawfully, to compress them without destroying invariants, and to refuse extrapolation beyond jurisdiction. These properties are not optional. They are the conditions under which any adaptive system remains coherent when exposed to reuse, transfer, and scrutiny. This perspective aligns with early cybernetic and complexity-theoretic accounts of adaptive systems as processes governed by constraint rather than by static description \parencite{ashby1956,weaver1948}.


A secondary but unavoidable consequence follows. If intelligence itself depends on regulated interaction and semi-permeable boundaries, then the communication of intelligence---including the publication of powerful ideas---must obey the same structural logic. Unfiltered disclosure is not inherently virtuous; neither is concealment inherently responsible. What matters is whether the form of disclosure preserves the invariants that give the ideas meaning.

The argument proceeds in a deliberately cumulative manner. Early sections establish ontological commitments regarding events, states, and construction history. Subsequent sections develop abstraction as invariant-preserving compression, modularity as an ontological requirement, and refusal as a first-class operation. Only after these constraints are in place does the essay address general intelligence, legibility, biological and computational boundary conditions, and the ethics of publication.

The structure of the essay is not incidental. Later claims depend on earlier constraints, and no section is intended to stand alone. This is not a stylistic choice but a substantive one: intelligence that can be meaningfully summarized without discipline is not the kind of intelligence under consideration.

% --------------------------------------------------
\section{Events Over States}
% --------------------------------------------------

\subsection{The Insufficiency of State-Based Accounts}

Most contemporary theories of intelligence, whether biological or artificial, are formulated in terms of states. Neural activations, parameter vectors, symbolic configurations, or world models are treated as the primary bearers of meaning and competence. Learning, on such accounts, consists in moving through a space of states toward configurations that optimize some criterion.

This framing obscures a fundamental asymmetry. A state is always a summary. It collapses history, erases order, and forgets the contingencies by which it was produced. Two systems may occupy indistinguishable states while having arrived there through radically different processes, with radically different implications for reuse, generalization, and failure.

State-based descriptions therefore lack explanatory power with respect to persistence. They can describe what a system \emph{is like} at a moment, but not what it \emph{can survive}. Intelligence, however, is not defined by momentary adequacy. It is defined by the ability to remain coherent across time, exposure, and reuse, a point emphasized early in cybernetic and complexity-theoretic treatments of adaptive systems \parencite{ashby1956,weaver1948}.


\subsection{Construction History as Primary}

To address this limitation, we take \emph{events} rather than states as ontologically prior. An event is an irreversible contribution to construction history: an observation made, a commitment taken, a refusal issued, a structure compressed. States, where they appear, are projections derived from histories under particular queries and scopes.

\begin{definition}
A \emph{construction history} is an ordered, irreversible sequence of events from which any state description is derivable only as a partial projection.
\end{definition}

On this view, memory is not storage but replayability. To remember is to be able to reconstruct how a structure came to be, not merely to access its current form. Learning is the reorganization of construction history into forms that are cheaper to reuse without loss of function, consistent with accounts that treat learning as transformation of process rather than accumulation of representations \parencite{ashby1956}.

This shift has immediate consequences. Intelligence can no longer be identified with static representations, nor can learning be reduced to parameter adjustment. What matters is the system's ability to transform its own history into reusable abstractions while preserving the conditions under which those abstractions remain valid.

\begin{remark}
Throughout what follows, any appeal to a \enquote{state} should be understood as shorthand for a view compiled from construction history under explicit constraints. No state is treated as ontologically primitive.
\end{remark}

\subsection{Irreversibility, Time, and Constraint Accumulation}

Treating events as primary commits the theory to irreversibility. An event, once incorporated into construction history, cannot be undone without altering the identity of the system that incorporates it. This irreversibility is not an implementation detail but a structural feature: it is what gives time its direction and learning its cost, echoing foundational analyses of irreversibility in complex adaptive systems \parencite{weaver1948}.

In a state-based account, time is often treated as an index labeling successive configurations. In an event-based account, time is instead the accumulation of constraints. Each event narrows the space of future admissible constructions by fixing commitments, excluding alternatives, and conditioning subsequent possibilities. Learning therefore increases not only competence but responsibility: what has been built constrains what may coherently follow.

This perspective clarifies why intelligence cannot be adequately characterized by instantaneous performance. A system that performs well only by discarding its history, resetting its commitments, or erasing prior structure is not intelligent in the relevant sense. It is merely reactive. Intelligence is distinguished by the capacity to carry constraints forward without collapse.

\subsection{Why Compression Requires History}

Compression plays a central role in most theories of intelligence, but it is often misunderstood as a purely representational operation. On the present account, compression is inseparable from history. To compress is not merely to shorten a description, but to replace a detailed construction history with a more economical one that can be replayed to the same effect under specified conditions.

Such replacement is only meaningful relative to what is being preserved. A compressed history is not a lossless encoding of all prior detail; it is a commitment to ignore certain distinctions while maintaining others. These commitments are intelligible only when the original history remains, at least in principle, reconstructible, a requirement closely related to information-theoretic treatments of compression as invariance under transformation \parencite{jaynes2003,cover_thomas2006}.

Compression without history degenerates into pattern matching. It may succeed locally, but it cannot support lawful reuse, because the reasons for the pattern’s validity have been erased. A genuinely intelligent system therefore compresses its history while retaining the ability to justify that compression relative to the constraints it preserves.

\subsection{Event-Based Identity and Generalization}

An immediate consequence of the event-based view is that identity becomes path-dependent. Two systems with identical outward behavior may nonetheless differ profoundly in what they can safely generalize, because their construction histories differ. What one system can extend lawfully, another may only approximate dangerously.

Generalization, on this account, is not the application of a rule to new cases, but the transport of a construction across contexts while preserving its enabling conditions. Such transport presupposes knowledge of how the construction was achieved in the first place. Without access to construction history, there is no principled way to determine whether reuse is valid or merely coincidental.

This observation already rules out a wide class of naïve general intelligence proposals. Any approach that treats learned structure as context-free, or that discards the conditions of its acquisition, forfeits the ability to regulate its own extension. What appears as flexibility in the short term becomes fragility under exposure.

\subsection{Consequences for the Structure of the Argument}

The remainder of this essay builds on the commitments established here. By treating events as ontologically prior to states, we commit to a conception of intelligence that is cumulative, constraint-sensitive, and irreducibly historical. Abstraction, modularity, refusal, and legibility will all be shown to follow from this starting point, not as independent principles but as necessary consequences.

Readers accustomed to state-based or representation-centric accounts may find this shift initially disorienting. That disorientation is itself diagnostic. Any framework that seeks to explain intelligence without accounting for the cost and irreversibility of construction has already abstracted away the very phenomenon it purports to explain.

In the next section, abstraction will be reconsidered under these constraints. Rather than treating abstraction as representational simplification, it will be developed as the identification of invariants under lawful transformation—a move that preserves the primacy of history while enabling reuse \parencite{arnold1989,olver1993}.

% --------------------------------------------------
\section{Modularity as Ontology, Not Convenience}
% --------------------------------------------------

\subsection{Why Monolithic Intelligence Fails}

It is tempting to imagine intelligence as a single, unified faculty: a global workspace, a central optimizer, or a comprehensive world model in which all information is integrated and adjudicated. Such monolithic conceptions are attractive because they promise coherence by fiat. If all distinctions collapse into a single representational space, then conflict, inconsistency, and ambiguity appear tractable.

This promise is illusory. A monolithic system has no principled way to regulate interaction between heterogeneous processes, because all interactions are already internal. As a result, every change propagates everywhere. Local failure becomes global corruption. The system gains expressive power at the cost of fragility, a trade-off long recognized in cybernetic analyses of large adaptive systems \parencite{ashby1956}.

More importantly, monolithic intelligence cannot generalize safely. Without internal boundaries, there is no mechanism to prevent abstractions learned in one regime from being applied illegitimately in another. What appears as flexibility in small domains becomes catastrophic overreach as scope expands, a failure mode familiar from both biological and engineered systems \parencite{weaver1948}.

\subsection{Modularity as a Structural Requirement}

Modularity is often introduced as an engineering strategy: a way to manage complexity, enable parallel development, or improve maintainability. In the present framework, modularity is not optional and not pragmatic. It is ontological.

\begin{definition}
A system is \emph{modular} if it can be decomposed into subsystems whose internal coherence does not depend on global synchronization, and whose interactions are mediated exclusively by explicit interfaces.
\end{definition}

Each module constitutes a locally coherent domain with its own construction history, abstractions, and refusal conditions. Modules may interact, but only through transformations that preserve the invariants of both sides. No module is privileged by default; no global authority resolves conflicts by erasing distinctions.

This separation is what allows abstraction to remain lawful under reuse. By forcing interactions to pass through interfaces, the system makes scope explicit and prevents accidental generalization, consistent with classical principles of separation and constraint in complex systems design \parencite{saltzer_schroeder1975}.

\subsection{Interfaces, Jurisdiction, and Scope}

An interface is not merely a channel for data exchange. It is a declaration of jurisdiction. It specifies what kinds of transformations are permitted, what kinds of commitments may be imported, and what kinds of effects may be exported.

Jurisdictional boundaries are the modular analogue of physical membranes. They do not block interaction; they regulate it. By constraining how information and influence cross module boundaries, interfaces preserve local coherence while enabling coordination, paralleling the role of semi-permeable boundaries in biological and cognitive systems \parencite{friston2010,friston2015}.

This has a crucial consequence for learning. When a module fails, the failure can be localized. Its construction history can be revised without invalidating unrelated structures. The system learns without unlearning everything else.

\subsection{Why Global Workspaces Are Insufficient}

Global workspace theories attempt to reconcile modularity with unity by positing a shared representational arena into which local processes broadcast their contents. While such architectures can support coordination, they reintroduce the very fragility modularity is meant to avoid.

Once information enters a global workspace, it becomes available everywhere, regardless of whether the receiving processes share the assumptions under which it was produced. Scope is lost. Refusal becomes difficult, because the system lacks a principled way to prevent uptake, a limitation noted in critiques of globally shared control architectures \parencite{ashby1956}.

In contrast, a genuinely modular system does not require a global workspace to achieve coherence. Coordination emerges from structured interaction among modules, not from universal exposure.

\subsection{Modularity and the Accumulation of Constraints}

Because modules maintain their own construction histories, they accumulate constraints independently. This independence is essential for long-term adaptation. Different modules may explore different abstractions, maintain different buffers of variation, and refuse different classes of transformation.

The system as a whole benefits from this diversity. It can compose modules when their invariants align and keep them separate when they do not. General intelligence arises not from homogenization, but from the disciplined management of heterogeneity, a theme that recurs across studies of complex adaptive systems \parencite{weaver1948}.

\subsection{Transition to Refusal}

Modularity alone is insufficient unless the system can decline illegitimate interaction. Interfaces must not only specify what is allowed; they must also make refusal possible when constraints cannot be preserved.

In the next section, refusal will be developed as a first-class cognitive operation. Rather than treating refusal as failure or ignorance, it will be shown to be a necessary condition for coherent modular interaction and, ultimately, for general intelligence.


% --------------------------------------------------
\section{Refusal as a First-Class Cognitive Operation}
% --------------------------------------------------

\subsection{Refusal Is Not Failure}

Within many accounts of intelligence, refusal is treated implicitly as a defect: an absence of knowledge, an error condition, or a temporary limitation to be overcome by improved optimization. Systems are evaluated by how rarely they fail to produce an answer or an action. Silence, hesitation, or constraint are framed as shortcomings.

This framing is incompatible with any conception of intelligence that is cumulative and general. A system that never refuses has no mechanism to protect the invariants that make its abstractions meaningful. It cannot distinguish between domains where reuse is lawful and domains where it is destructive. Apparent competence in such a system is purchased by borrowing against hidden fragility.

Refusal, properly understood, is not the negation of intelligence. It is one of its essential expressions.

\subsection{Refusal as Jurisdictional Enforcement}

Every abstraction has a domain of validity, whether acknowledged or not. To apply an abstraction outside that domain is to violate the conditions under which it was constructed. A system that generalizes without checking these conditions will eventually collapse its own coherence.

Refusal is the operation by which a system enforces jurisdiction. It is the recognition that no admissible transformation exists between a current context and the contexts in which a given abstraction is known to hold.

\begin{definition}
A \emph{refusal} is the structurally grounded non-existence of an admissible transformation between a proposed action or inference and the system's preserved invariants.
\end{definition}

This definition is deliberately negative. Refusal is not an alternative action chosen from a menu. It is the absence of a lawful path forward.

\subsection{Uncertainty, Irreversibility, and Risk}

Refusal becomes especially important in the presence of irreversibility. When an action or inference cannot be undone without corrupting construction history, the cost of error increases dramatically. Under such conditions, approximation is not a virtue; it is a liability.

A system that treats uncertainty as a reason to guess rather than to suspend commits itself to irreversible commitments it may later be unable to repair. By contrast, a system that can refuse preserves optionality. It delays commitment until sufficient structure exists to justify action.

This capacity to delay is not passivity. It is a form of active constraint management.

\subsection{Refusal and Learning}

Refusal plays a central role in learning precisely because learning involves revision. To revise a construction, the system must be able to identify which prior commitments remain valid and which must be set aside. Without refusal, all commitments are treated as equally binding, and revision becomes destructive rather than selective.

When a system refuses, it marks a boundary in its own competence. That boundary becomes informative. It directs exploration, motivates the acquisition of new constraints, and guides the construction of new abstractions. Refusal is therefore not the end of learning, but its compass.

\subsection{Refusal in Modular Systems}

In a modular architecture, refusal prevents the collapse of scope. When one module proposes an interaction that another cannot support without violating its invariants, refusal blocks composition. This preserves local coherence and prevents error from propagating globally.

Importantly, refusal need not be symmetric. One module may accept a transformation that another must reject. Such asymmetry is not inconsistency; it reflects differing construction histories and jurisdictions. Coherence is maintained not by forcing agreement, but by respecting boundaries.

\subsection{Refusal as a Condition of Generality}

Generality is often conflated with permissiveness: the ability to act across many domains with minimal restriction. On the present account, the opposite is true. A system is general to the extent that it can distinguish where its abstractions apply and where they do not.

A system that always acts is not general. It is reckless.

A system that refuses indiscriminately is not general. It is inert.

General intelligence occupies the narrow regime in which refusal is selective, justified, and structurally grounded.

\subsection{Transition to Transfer and Generality}

Once refusal is recognized as a first-class operation, the problem of general intelligence can be posed more precisely. The question is no longer how to build a system that acts everywhere, but how to build a system that transfers structure lawfully across contexts while refusing illegitimate reuse.

In the next section, general intelligence will be characterized in these terms: not as breadth of competence, but as the regulated transport of invariant structure under constraint.

% --------------------------------------------------
\section{Generality as Lawful Transfer}
% --------------------------------------------------

\subsection{Against Breadth as a Criterion of Generality}

Generality is commonly identified with breadth: the number of domains, tasks, or environments in which a system performs adequately. On such accounts, intelligence becomes a matter of coverage. A system is more general insofar as it succeeds in more places.

This criterion is misleading. Breadth alone cannot distinguish between lawful reuse and accidental success. A system may perform well across many domains by relying on shallow correlations, heuristics, or brute-force adaptation, while lacking any principled understanding of why those strategies work or where they fail. Such systems generalize until they do not, and when they fail, they fail catastrophically.

A more demanding criterion is required—one that distinguishes genuine transfer from coincidental overlap.

\subsection{Transfer as the Transport of Construction}

On the event-based account developed earlier, generalization is not the application of a static rule to new cases, but the transport of a construction from one context to another. This transport is only legitimate if the conditions that made the construction successful in its original domain are preserved, or suitably transformed, in the new one.

Transfer therefore presupposes knowledge of construction history. A system must know not only what worked, but why it worked, and under what constraints. Without this knowledge, reuse becomes guesswork.

\begin{definition}
A \emph{lawful transfer} is a transformation of a construction history from one context to another that preserves the invariants required for its validity.
\end{definition}

Lawful transfer is conservative. It does not promise success everywhere. It promises coherence where it applies and refusal where it does not.

\subsection{Invariants as the Currency of Generality}

Invariants play a central role in distinguishing lawful transfer from overgeneralization. An invariant is a property of a construction that remains stable under a specified family of transformations. These transformations encode what counts as a permissible change of context.

A system that cannot articulate, even implicitly, which invariants it is preserving cannot regulate its own generalization. It may apply an abstraction successfully in familiar regimes, but it has no principled way to detect when it has left those regimes.

Generality, on this view, is proportional not to the number of abstractions a system possesses, but to the number of invariants it can preserve under transformation.

\subsection{Why Transfer Requires Modularity and Refusal}

Lawful transfer cannot be centralized without collapsing distinctions. If a single global mechanism adjudicates all reuse, then all contexts are implicitly treated as commensurable. This undermines the very notion of invariance.

Instead, transfer must be mediated by modules that maintain local coherence. Each module evaluates proposed transformations relative to its own construction history and invariants. When alignment exists, transfer proceeds. When it does not, refusal blocks propagation.

This distributed evaluation is what allows generality to scale without fragility. The system does not need to know in advance which transfers will succeed. It needs only to enforce refusal when constraints cannot be preserved.

\subsection{Failure Modes of Illegitimate Transfer}

When transfer is attempted without constraint, several characteristic failure modes arise. Abstractions become overextended, losing specificity until they are vacuous. Systems appear flexible until they encounter edge cases, at which point failure is abrupt and difficult to localize. Responsibility for error diffuses, because no boundary marks where reuse ceased to be valid.

These failures are not incidental. They follow necessarily from treating generality as permissiveness rather than as regulated transport.

\subsection{Generality Without Collapse}

A system that implements lawful transfer will appear conservative by contemporary standards. It will refuse often. It will decline to extrapolate without sufficient alignment. It will prioritize coherence over coverage.

Paradoxically, such a system is capable of deeper generality. Because it preserves its invariants, it can reuse constructions repeatedly without degradation. Its competence accumulates rather than dissolves.

This is the sense in which general intelligence should be understood: not as the absence of limits, but as the disciplined navigation of them.

\subsection{Transition to Locality and Context}

Lawful transfer presupposes an account of context. Invariants are preserved relative to transformations, and transformations are defined relative to local conditions. To make this precise, the next section develops a view of intelligence as locally coherent and only conditionally global.

Rather than assuming a single unified worldview, intelligence will be shown to arise from the structured coordination of partial perspectives under explicit gluing conditions.

% --------------------------------------------------
\section{Local Coherence and Conditional Globality}
% --------------------------------------------------

\subsection{Why Global Consistency Is the Wrong Ideal}

Many theories of intelligence implicitly assume that coherence requires global consistency: a single, unified model of the world in which all facts, beliefs, and abstractions are mutually compatible. In such frameworks, inconsistency is treated as a defect to be eliminated, and intelligence is equated with the capacity to resolve all local discrepancies into a coherent whole.

This ideal is misplaced. In systems that learn, adapt, and operate across heterogeneous environments, global consistency is neither achievable nor desirable. Different contexts impose different constraints, admit different abstractions, and tolerate different approximations. Forcing these into a single globally consistent framework often requires discarding precisely the information that makes local reasoning effective.

Intelligence does not require global consistency. It requires \emph{local coherence} and principled criteria for when local constructions may, or may not, be combined.

\subsection{Local Coherence as the Unit of Sense}

A locally coherent construction is one whose internal abstractions, constraints, and refusals are mutually compatible within a defined scope. Such a construction may rely on assumptions that do not hold elsewhere, and it may tolerate inconsistencies that would be unacceptable outside its jurisdiction.

Local coherence is not a weakness. It is what allows intelligence to function in environments that are themselves fragmented, non-stationary, and partially observable. By maintaining multiple locally coherent structures rather than a single global one, a system preserves flexibility without sacrificing rigor.

This perspective reframes contradiction. Apparent inconsistencies between local constructions are not necessarily errors. They are signals that different invariants are being preserved under different conditions.

\subsection{Context as Boundary, Not Background}

Context is often treated as ancillary information that modifies the interpretation of otherwise universal rules. On the present account, context is primary. It defines the boundary conditions under which abstractions are valid and transfers are lawful.

A context is not merely a set of parameters. It is a structured environment with its own admissible transformations and refusal conditions. To move between contexts is to cross a boundary, and not all boundaries are traversable.

This makes explicit why abstraction cannot be context-free. Any abstraction that purports to apply universally without qualification has already erased the conditions of its own validity.

\subsection{Gluing and the Limits of Integration}

While global consistency is neither required nor attainable, intelligence does require coordination across contexts. Local constructions must sometimes be combined to support action, explanation, or learning at larger scales. The challenge is to determine when such combination is legitimate.

Combination is legitimate only when local constructions agree on the overlaps that matter for the task at hand. Where such agreement exists, local structures may be \emph{glued} together to form a larger coherent whole. Where it does not, separation must be maintained.

This criterion replaces the demand for universal consistency with a demand for conditional compatibility. Integration is not assumed; it is earned.

\subsection{Failure Modes of Forced Globality}

When systems attempt to impose global coherence prematurely, characteristic failures occur. Local distinctions are flattened, leading to abstractions that are broadly applicable but weakly informative. Conflicts are resolved by erasure rather than reconciliation, obscuring the reasons for disagreement. Errors propagate widely because boundaries that would have contained them have been removed.

These failures are especially damaging in general systems, where errors are reused across domains. What appears as elegance in design becomes brittleness in operation.

\subsection{Conditional Globality as an Achievement}

On the present account, global structure is not a starting point but an outcome. It emerges only where local constructions align sufficiently to support integration. Even then, such globality remains conditional. It may dissolve as contexts change or new constraints arise.

This view aligns with the broader theme of the essay. Intelligence is not the elimination of boundaries, but their disciplined management. Coherence is not imposed from above; it is negotiated across levels.

\subsection{Transition to Legibility and Exposure}

Once intelligence is understood as locally coherent and only conditionally global, the problem of legibility takes on a new form. Making a construction legible outside its original context is itself a kind of transfer. It risks erasing boundaries, flattening constraints, and inviting illegitimate reuse.

In the next section, legibility will be treated as a selection pressure acting on intelligent systems. The capacity to regulate what is made visible, when, and under what conditions will be shown to be as essential as the capacity to act or infer.

% --------------------------------------------------
\section{Legibility as a Selection Pressure}
% --------------------------------------------------

\subsection{Legibility Is Not Neutral}

Legibility is often treated as an unqualified good. To be legible is to be understood, reproduced, and adopted. In scientific, technical, and public discourse alike, there is a presumption that increasing legibility increases value. Systems, theories, and explanations are praised to the extent that they are accessible, transparent, and easily summarized.

This presumption ignores a fundamental asymmetry. Making a structure legible does not merely reveal it; it alters the environment in which it operates. Once legible, a construction becomes subject to extraction, recombination, and reuse by agents that may not share the constraints under which it was built. Legibility therefore functions as an exposure mechanism.

From an evolutionary perspective, exposure is not benign. It creates new selection pressures that act on the system itself.

\subsection{Competence Increases Targeting}

In biological systems, increased competence often correlates with increased visibility. Bright coloration, complex behavior, or pronounced structure may confer advantages in coordination or reproduction, but they also attract predation. The same trait that signals fitness can become a liability when the environment changes.

This dynamic generalizes. Any system that demonstrates capability creates surface area. It becomes easier to exploit, copy, attack, or repurpose. Intelligence that cannot regulate its own visibility will be selected against, not because it lacks power, but because it cannot survive its own success.

Legibility is therefore not merely communicative. It is ecological.

\subsection{Legibility as an Internal Control Problem}

If exposure alters the environment, then the decision to expose must itself be regulated. For an intelligent system, legibility becomes an internal control variable alongside action and inference.

To make something legible is to choose a projection of internal structure into an external context. Different projections preserve different invariants and discard different constraints. A full exposition may support deep collaboration in trusted contexts while becoming dangerous in adversarial or extractive ones. A minimal projection may preserve safety at the cost of utility.

There is no universally correct level of legibility. What matters is that the choice be constrained, justified, and reversible where possible.

\subsection{Camouflage and Signaling}

Biological systems exhibit two complementary strategies for managing legibility: camouflage and signaling. Camouflage reduces visibility to avoid exploitation, while signaling amplifies specific traits to coordinate with allies or attract mates. Both are adaptive responses to selection pressure.

Crucially, these strategies are not expressions of intent or deception. They are regulatory mechanisms. The same organism may employ both, depending on context.

Intelligence exhibits the same duality. There are contexts in which displaying capability accelerates coordination and learning, and contexts in which concealment preserves coherence. A system that can do only one or the other is brittle.

\subsection{Why Unregulated Legibility Is Fragile}

When legibility is treated as an unconditional virtue, systems are incentivized to collapse structure into forms that travel easily. Explanations become slogans, abstractions become heuristics, and architectures become recipes. What survives exposure is not what is robust, but what is portable.

This dynamic selects against constraint. Systems that preserve invariants resist summarization and are penalized for opacity. Systems that discard constraints gain adoption at the cost of correctness. Over time, the environment fills with ideas that are easy to reuse and hard to repair.

From the perspective developed in this essay, this is not progress. It is a form of epistemic drift.

\subsection{Legibility and the Risk of Illegitimate Transfer}

Making a construction legible outside its original context invites transfer. If the conditions of validity are not preserved, such transfer becomes illegitimate. The resulting failures are often attributed to misuse or misunderstanding, but structurally they arise from boundary collapse.

An intelligent system must therefore treat legibility itself as a form of transfer, subject to the same criteria as action or inference. Where invariants cannot be preserved, exposure must be limited or delayed.

\subsection{Transition to Boundary Conditions}

The regulation of legibility is not an ad hoc defensive maneuver. It follows from the same structural principles that govern biological membranes, neural synchronization, and modular cognition. To make this continuity explicit, the next section examines boundary conditions across substrates, showing how semi-permeable boundaries, buffering, and refusal recur wherever intelligence persists under selection pressure.

% --------------------------------------------------
\section{Boundary Conditions Across Substrates}
% --------------------------------------------------

\subsection{Boundaries as Conditions of Persistence}

The regulation of legibility developed in the previous section is not a peculiarity of social or epistemic systems. It is a special case of a more general requirement: any system that persists under selection pressure must instantiate boundaries that are neither rigid barriers nor unrestricted channels. These boundaries regulate exchange, preserve internal gradients, and prevent uncontrolled propagation of perturbation.

A boundary, in this sense, is not defined by separation alone. It is defined by \emph{selective permeability}. What matters is not whether interaction occurs, but under what conditions it is admitted, delayed, transformed, or refused.

This requirement recurs across biological, neural, computational, and epistemic domains. Its manifestations differ in material realization, but its structural role is invariant.

\subsection{Cell Membranes and Ion Channels}

At the cellular level, life depends on membranes that maintain electrochemical gradients. These gradients are not passive features of matter; they are actively regulated through ion channels whose opening and closing is context-sensitive. The cell survives by allowing some exchanges while preventing others, and by doing so at rates that preserve internal coherence.

Total openness would collapse the gradient and destroy the cell’s capacity to perform work. Total closure would prevent adaptation and starve the cell of information and resources. The membrane therefore enforces a narrow regime in which selective exchange sustains function.

The lesson is structural rather than biological. Work, communication, and adaptation require differences to be maintained. Boundaries exist to protect those differences.

\subsection{Cortical Synchronization and Markov Blankets}

In nervous systems, boundaries reappear as patterns of synchronization and desynchronization among neural populations. Cortical regions are not globally synchronized at all times. Instead, they couple transiently through oscillatory alignment, forming functional assemblies that dissolve as conditions change.

These assemblies are often described in terms of Markov blankets: sets of variables that mediate interaction between a subsystem and its environment while shielding internal states from direct perturbation. The blanket does not block influence; it structures it.

Temporal gating plays the role of refusal. Signals that arrive out of phase are ignored or delayed. Information passes only when timing constraints align. Coherence is maintained not by global integration, but by regulated coupling.

\subsection{Redundancy and Noncoding Structure in Evolution}

At the scale of evolution, boundaries take the form of redundancy and buffering. Genomes contain large regions of noncoding material that do not directly specify phenotypic traits. These regions are often described as waste, but this description is misleading.

Redundant and noncoding sequences provide a buffer against mutation. They allow variation to occur without immediately corrupting essential functions. Over time, such variation may be co-opted into new structures, but only after selection has filtered it.

Evolution thus relies on apparent inefficiency to preserve long-term adaptability. Constraint is not imposed by minimizing variation, but by regulating its exposure to selection.

\subsection{Policy Selection and Latent Variation}

In cognitive and artificial systems, similar buffering appears as latent policy space. An intelligent system does not act on every possible policy it can generate. Instead, it maintains internal variation while exposing only a small subset of actions to the environment.

Policy selection functions as a boundary. It evaluates potential actions relative to constraints, suppresses those that violate jurisdiction, and delays commitment where uncertainty is high. Much of the system’s internal computation never becomes externally visible.

This apparent waste is functional. Without it, exploration would be destructive rather than informative, and learning would collapse into immediate exploitation.

\subsection{Boundaries as Constraints on Transfer}

Across these substrates, the role of boundaries is consistent. They regulate transfer: of matter, of energy, of information, of influence. Transfer that is too permissive destroys internal structure; transfer that is too restrictive prevents adaptation.

The optimal regime is not fixed. It depends on context, history, and threat. Boundaries must therefore be dynamically regulated rather than statically imposed.

This dynamic regulation is precisely what distinguishes living, learning, and intelligent systems from inert ones.

\subsection{Transition to Formalization}

The recurrence of semi-permeable boundaries across domains suggests that the phenomenon is not contingent but necessary. To make this necessity precise, the next section introduces a formal characterization of boundaries, refusal, and invariance. Rather than appealing to metaphor, it will articulate the structural conditions under which adaptive systems remain coherent under reuse and exposure.

% --------------------------------------------------
\section{Formalizing Boundaries, Invariants, and Refusal}
% --------------------------------------------------

\subsection{Why Formalization Is Necessary}

Up to this point, the argument has proceeded by structural analysis across domains. The recurrence of semi-permeable boundaries, buffering, and refusal suggests that these are not contingent design choices but necessary conditions for persistence under selection pressure. However, without formalization, this necessity remains suggestive rather than binding.

Formalization serves a specific role here. It is not introduced to increase precision for its own sake, nor to provide executable specifications. Its function is to make explicit which transformations are admissible, which are not, and why. In doing so, it enforces scope and prevents illegitimate generalization.

The formalism employed is deliberately minimal. It aims to capture invariance and refusal without presupposing any particular substrate, representation, or implementation.

\subsection{Objects, Transformations, and Invariants}

We begin by treating locally coherent subsystems as abstract entities and interactions between them as transformations. What matters is not the internal constitution of these entities, but the conditions under which interactions preserve coherence.

\begin{definition}
Let an \emph{object} denote a locally coherent construction, characterized by a construction history and a set of preserved invariants.
\end{definition}

\begin{definition}
A \emph{transformation} between two objects is admissible if it preserves the invariants required for the coherence of both source and target.
\end{definition}

Invariants may encode conservation laws, semantic constraints, timing relations, jurisdictional limits, or other conditions discovered through construction history. They are not assumed to be universal. Each object may preserve a different family of invariants.

\subsection{Admissibility and the Non-Existence of Paths}

A crucial feature of this framework is that not all pairs of objects admit admissible transformations. The absence of a lawful path is not a failure of the formalism; it is its central expressive feature.

\begin{definition}
A \emph{refusal} occurs when no admissible transformation exists between a proposed interaction and the invariants preserved by an object.
\end{definition}

Refusal is thus modeled negatively. It is not a special action or signal. It is the recognition that a transformation cannot be composed without violating coherence.

This treatment avoids a common pitfall. If refusal were modeled as an ordinary operation, it would itself be subject to misuse or overextension. By contrast, modeling refusal as non-existence makes it structurally enforced rather than procedurally optional.

\subsection{Boundaries as Restricted Domains of Interaction}

Boundaries arise naturally from admissibility constraints. For any object, the set of admissible transformations defines a domain of interaction. Outside this domain, interactions are refused.

This yields a notion of semi-permeability. Some interactions are allowed, others are not, and the distinction depends on preserved invariants rather than on external authority or global rules.

Dynamic regulation enters through the evolution of invariants. As construction histories change, invariants may be strengthened, weakened, or refined. What was once admissible may later be refused, and vice versa. Boundaries are therefore not static walls but evolving constraints.

\subsection{Buffering and Redundancy}

The formal framework also accommodates buffering. Redundant internal structure corresponds to alternative constructions or latent transformations that are not currently admissible but may become so under future refinement of invariants.

Such redundancy is essential for adaptation. Without it, the system would have no internal degrees of freedom with which to explore new admissible interactions. With it, variation can occur internally without immediate exposure to irreversible external consequences.

Buffering therefore appears not as inefficiency, but as the formal precondition for learning under constraint.

\subsection{Implications for General Intelligence}

Within this framework, general intelligence is not characterized by the existence of many transformations, but by the system’s capacity to regulate admissibility. A system is general to the extent that it can:

\begin{itemize}
\item identify which invariants matter in a given context,
\item evaluate proposed transformations against those invariants,
\item refuse interactions that violate coherence,
\item and revise its invariants through construction without collapse.
\end{itemize}

This definition is deliberately conservative. It privileges coherence over coverage and refusal over indiscriminate action. Yet it is precisely this conservatism that allows competence to accumulate rather than dissolve.

\subsection{Transition to the Boundary Lemma}

The formal considerations developed here allow the recurring boundary phenomena observed earlier to be stated as a general structural result. In the next section, this result is expressed as a lemma capturing the necessity of semi-permeable boundaries for any system that remains adaptive under selection pressure.

The lemma does not depend on biology, neuroscience, or computation in particular. It follows from the minimal requirements of invariance, interaction, and persistence.

% --------------------------------------------------
\section{The Semi-Permeable Boundary Lemma}
% --------------------------------------------------

\subsection{Statement of the Lemma}

The preceding sections have introduced the minimal formal machinery required to speak precisely about interaction, invariance, and refusal without committing to any particular substrate. Within that framework, the following result can now be stated.

\begin{lemma}[Semi-Permeable Boundary Lemma]
Any system capable of sustained adaptation under selection pressure must instantiate boundaries that are:
\begin{enumerate}
\item selectively permeable, admitting some interactions while refusing others,
\item dynamically regulated, with admissibility varying by context and history,
\item buffering, maintaining redundant or latent internal structure,
\item constraint-preserving, preventing transformations that would destroy coherence.
\end{enumerate}
Such boundaries are not implementation artifacts but structural necessities. In their absence, invariants collapse and adaptive capacity is lost.
\end{lemma}

This lemma does not assert that all adaptive systems look alike. It asserts that any system which remains coherent under reuse and exposure must satisfy these conditions in some material or formal realization.

\subsection{Justification by Structural Necessity}

The lemma follows from the minimal requirements of interaction and persistence. A system that adapts must exchange information or influence with its environment; otherwise it cannot respond to change. Yet if this exchange is unrestricted, internal distinctions erode faster than they can be reconstructed. The system loses the gradients upon which work, prediction, and learning depend.

Selective permeability resolves this tension. It allows interaction while preserving difference. Dynamic regulation is required because the environment is not static; what is admissible under one set of conditions may be destructive under another. Buffering is required because adaptation proceeds through variation and selection, which demand internal slack. Constraint preservation is required because invariants are the currency of reuse.

None of these requirements can be relaxed independently. Removing any one collapses the regime in which adaptation is possible.

\subsection{Non-Existence as a Positive Condition}

A key feature of the lemma is its treatment of refusal. Refusal appears not as a compensatory mechanism added to an otherwise permissive system, but as the structural non-existence of certain interactions.

This is counterintuitive only if one assumes that capability consists in the availability of options. On the present account, capability consists in the availability of \emph{lawful} options. The absence of an unlawful transformation is therefore not a limitation, but a condition of coherence.

Boundaries enforce this absence. They do not need to represent what is forbidden; they simply do not admit it.

\subsection{Substrate Independence}

The lemma is deliberately substrate-neutral. It applies equally to:
\begin{itemize}
\item biological systems maintaining metabolic gradients,
\item neural systems coordinating through oscillatory synchrony,
\item evolutionary systems buffering variation through redundancy,
\item computational systems enforcing privilege separation,
\item epistemic systems regulating disclosure and reuse.
\end{itemize}

In each case, the material realization differs, but the structural role is identical. Where boundaries fail, systems either stagnate or disintegrate.

\subsection{Transition to Scope and Refusal}

The lemma establishes boundaries as a necessary condition for adaptation. It remains to show how these boundaries operate internally in intelligent systems. In particular, how scope is determined, and how refusal functions as a boundary operator rather than as a failure mode.

The next section develops this consequence formally, showing that scope restriction and refusal are not optional safeguards, but constitutive features of any general intelligence.

% --------------------------------------------------
\section{Scope, Refusal, and Boundary Operators}
% --------------------------------------------------

\subsection{From Boundaries to Scope}

The Semi-Permeable Boundary Lemma establishes that adaptive systems must regulate interaction. For intelligent systems, this regulation appears internally as \emph{scope}. Scope determines where a construction, abstraction, or policy applies, and where it does not.

Scope is not an annotation added after the fact. It is an emergent property of construction history. Each abstraction inherits the conditions under which it was formed, refined, and validated. These conditions delimit the contexts in which reuse remains lawful.

A system that cannot track scope implicitly treats all contexts as equivalent. This is not generality; it is indiscrimination.

\subsection{Scope as a Boundary Operator}

Within the formal framework introduced earlier, scope functions as a boundary operator on admissible transformations. It restricts the domain in which morphisms may exist by enforcing invariants derived from construction history.

\begin{definition}
The \emph{scope} of a construction is the set of contexts for which admissible transformations preserving its invariants exist.
\end{definition}

Outside this set, no lawful transformation exists. Attempted reuse is therefore refused, not because the system lacks capacity, but because the required invariants cannot be preserved.

Scope thus encodes both competence and its limits. To know what one can do is inseparable from knowing where that doing remains valid.

\subsection{The Scope--Refusal Corollary}

The relationship between boundaries, scope, and refusal can now be stated explicitly.

\begin{corollary}[Scope--Refusal Corollary]
In any system capable of general intelligence, scope restriction and refusal are necessary boundary operators. A system that lacks mechanisms to:
\begin{enumerate}
\item determine the scope of its abstractions, and
\item refuse actions, inferences, or disclosures outside that scope,
\end{enumerate}
cannot preserve its invariants under reuse and therefore cannot remain coherent as it generalizes.
\end{corollary}

This corollary follows directly from the Semi-Permeable Boundary Lemma. If boundaries are required for adaptation, and if scope determines where boundaries apply internally, then refusal is the operation by which scope is enforced.

\subsection{Refusal as Structural Non-Existence}

It is important to emphasize that refusal is not implemented as a special case or exception. In the formal account, refusal corresponds to the non-existence of an admissible transformation. This makes refusal robust. It cannot be overridden by optimization pressure or convenience, because there is nothing to override.

This treatment also explains why refusal often appears unintuitive or frustrating to external observers. From outside the system, refusal looks like an absence of response. From inside, it is the only coherent response available.

\subsection{Asymmetry and Partial Applicability}

Scope need not be symmetric. A construction may apply in one direction but not in another; a transformation may preserve invariants in one context but violate them in reverse. Such asymmetries are common in biological, cognitive, and epistemic systems.

Recognizing this prevents a common error: assuming that applicability must be mutual or universal. General intelligence does not require symmetry. It requires discrimination.

\subsection{Implications for Learning and Revision}

Scope and refusal also govern revision. When a construction fails outside its scope, the system must decide whether to expand the scope by discovering new invariants, or to maintain refusal. Both options are legitimate. What matters is that expansion is earned through construction, not assumed by default.

Learning, on this view, is the gradual reshaping of scope through experience. Refusal marks the current boundary; exploration tests whether that boundary can be safely moved.

\subsection{Transition to Invariance Across Systems}

The corollary clarifies how boundaries operate within intelligent systems. The final step is to show that these same boundary operators recur across biological, neural, computational, and epistemic domains. This recurrence is not accidental. It reflects a deeper invariance.

In the next section, this invariance is stated as a general theorem unifying membranes, Markov blankets, privilege separation, and effort-gated legibility under a single structural principle.

% --------------------------------------------------
\section{The Boundary Invariance Theorem}
% --------------------------------------------------

\subsection{Statement of the Theorem}

The preceding analysis has shown that boundaries, scope, and refusal are necessary for coherent adaptation within individual systems. What remains is to show that these requirements are not domain-specific, but invariant across substrates. This can now be stated formally.

\begin{theorem}[Boundary Invariance Theorem]
Any system—biological, neural, computational, or epistemic—that remains adaptive under reuse, exposure, and selection pressure must implement boundary conditions satisfying all of the following:
\begin{enumerate}
\item selective permeability, admitting only admissible interactions,
\item buffering, maintaining latent or redundant internal structure,
\item dynamic regulation, with boundary conditions varying by context and history,
\item refusal, enforced as the non-existence of illegitimate transformations,
\item graded access, distinguishing inspection from modification.
\end{enumerate}
These conditions are invariant across substrate and scale. Systems that fail to satisfy them may exhibit short-term performance but cannot sustain general intelligence.
\end{theorem}

\subsection{Proof by Structural Correspondence}

The proof proceeds by demonstrating that each clause of the theorem is realized, in structurally equivalent form, across distinct domains.

\subsubsection{Biological and Neural Systems}

In biological systems, selective permeability is instantiated by cell membranes and ion channels that regulate the exchange of matter and charge. Buffering appears in metabolic reserves and noncoding genetic material, which allow variation without immediate functional loss. Dynamic regulation is achieved through context-sensitive channel gating and regulatory networks.

In neural systems, selective permeability appears as oscillatory synchronization that admits signals only under phase alignment. Markov blankets mediate interaction between internal and external states, enforcing refusal through desynchronization or inhibition. Graded access arises through layered processing, where sensory input may influence internal states without directly modifying long-term structure.

Failure of these mechanisms leads to loss of coherence, as seen in pathological synchronization or metabolic collapse.

\subsubsection{Computational Systems}

In computational systems, particularly operating systems, selective permeability is enforced through permission models. Read access allows inspection without modification; write and execute permissions regulate alteration. Privilege separation enforces graded access, requiring explicit escalation for operations that affect global state.

Buffering appears as redundancy, indirection layers, and sandboxed processes. Dynamic regulation occurs through runtime checks and context-dependent permissions. Refusal is enforced structurally: illegal system calls do not exist within unprivileged contexts.

Systems lacking such boundaries are not more powerful. They are less stable.

\subsubsection{Epistemic and Intelligent Systems}

In epistemic systems, selective permeability is realized through formal constraints, scope conditions, and effort-gated legibility. Buffering appears as redundancy in exposition, delayed conclusions, and non-operational formalism that preserves structure without enabling immediate deployment.

Dynamic regulation is achieved by varying levels of disclosure across contexts. Refusal appears as the absence of recipes, stepwise instructions, or context-free rules. Graded access distinguishes understanding from authority to modify or apply.

When these boundaries fail, ideas propagate without constraint, leading to distortion, misuse, and epistemic collapse.

\subsection{Non-Equivalence to Secrecy}

It is essential to distinguish boundary enforcement from secrecy. In all cases considered, the boundaries do not conceal structure; they regulate interaction. Inspection remains possible. What is restricted is modification, deployment, or transfer without constraint.

This distinction explains why effort-gated legibility is ethically cleaner than concealment. It preserves openness while preventing illegitimate reuse.

\subsection{Consequences for General Intelligence}

The theorem implies that general intelligence cannot be equated with maximal openness, maximal capability, or maximal transferability. It is characterized instead by the disciplined placement of boundaries that preserve invariants under reuse.

Any proposal for general intelligence that omits refusal, buffering, or graded access is structurally incomplete. Such systems may scale briefly, but they do not persist.

\subsection{Transition to Architectural Implications}

The Boundary Invariance Theorem completes the formal core of the argument. What remains is to articulate its consequences for the design and interpretation of general intelligence architectures, and for the ethics of publishing powerful ideas.

In the next section, these consequences are developed explicitly, not as prescriptions, but as architectural implications that follow from the invariants established here.

% --------------------------------------------------
\section{A Blueprint for General Intelligence Under Constraint}
% --------------------------------------------------

\subsection{Architectures, Not Recipes}

The Boundary Invariance Theorem places a strict limit on what it can mean to specify a general intelligence. Any attempt to present a stepwise procedure, an algorithmic recipe, or an operational checklist immediately violates the very constraints that make general intelligence coherent. What can be specified, instead, is an \emph{architecture}: a set of structural conditions that any admissible realization must satisfy.

An architecture constrains what may exist without dictating how it must be built. It describes invariants, interfaces, and refusal conditions rather than executable steps. This distinction is not rhetorical. It is the only way to speak meaningfully about general intelligence without collapsing it into extractable technique.

\subsection{Replayable Construction History}

A general intelligence must be grounded in replayable construction history. Its identity cannot be reduced to a static configuration or parameter set. Every competence it exhibits must be traceable to a sequence of irreversible events: observations, abstractions, compressions, and refusals.

States, where they appear, are projections compiled from this history under explicit scope. They are not authoritative. Learning consists in reorganizing history into forms that are cheaper to replay while preserving the invariants that justify reuse.

Any system that discards its history in order to optimize present performance forfeits generality.

\subsection{Strong Modularity and Jurisdiction}

The architecture must be modular in the strong sense developed earlier. Functional units maintain independent construction histories and preserve local invariants. No privileged global workspace exists in which all distinctions collapse.

Interaction occurs only through explicit interfaces that declare jurisdiction. These interfaces do not merely transmit information; they enforce scope. A module may inspect the outputs of another without acquiring the authority to modify its internal structure or to reuse its abstractions outside their domain of validity.

This separation is the condition under which learning accumulates rather than interferes with itself.

\subsection{Abstraction as Invariant-Preserving Compression}

Abstraction operates by replacing detailed construction histories with more economical ones that behave equivalently under admissible transformations. The architecture must therefore track not only abstractions, but the invariants they preserve and the transformations under which they remain valid.

Summarization and extension are the same operation viewed from opposite directions. Both are evaluated by preservation, not novelty. A general intelligence improves over time not by increasing the number of abstractions it holds, but by refining the invariants that govern their reuse.

\subsection{Lawful Transfer and Distributed Evaluation}

Generality is achieved through lawful transfer. Proposed reuse of a construction is evaluated locally by the modules involved, relative to their own invariants and construction histories. Where alignment exists, transfer proceeds. Where it does not, refusal blocks composition.

There is no centralized authority that forces generalization. Coherence emerges from distributed refusal.

This architecture scales because it fails locally. Errors are contained, diagnoses are possible, and revision does not require global rollback.

\subsection{Refusal as a Constitutive Operation}

Refusal is not an error condition or a safety override. It is a constitutive operation of the architecture. It appears whenever no admissible transformation exists between a proposed action, inference, or disclosure and the preserved invariants of the system.

Refusal preserves optionality under uncertainty and prevents irreversible commitments from being made without justification. A system that cannot refuse cannot remain coherent as it generalizes.

\subsection{Local Coherence and Conditional Globality}

The architecture maintains multiple locally coherent constructions that may or may not integrate. Global structure is not assumed. It is achieved only where gluing conditions are satisfied. Even then, such integration remains conditional and revisable.

This prevents the collapse of local constraints into globally inconsistent abstractions. It allows the system to operate effectively across heterogeneous domains without enforcing premature unification.

\subsection{Regulation of Legibility}

Finally, the architecture treats legibility as an internal control variable. External projections of internal structure are chosen relative to context, threat, and irreversibility. Different projections preserve different invariants.

The system may expose competence where coordination is beneficial and conceal structure where extraction would be destructive. This regulation is not deception. It is boundary maintenance.

\subsection{What This Blueprint Excludes}

This architectural characterization excludes, by necessity:
\begin{itemize}
\item monolithic objective functions,
\item unrestricted optimization,
\item context-free abstractions,
\item and unconditional disclosure.
\end{itemize}

These exclusions are not normative judgments. They follow directly from the boundary conditions required for persistence under reuse and exposure.

\subsection{Transition to Publication and Ethics}

The blueprint completes the internal characterization of general intelligence. What remains is to consider its external consequences. If intelligence itself depends on boundaries, refusal, and regulated transfer, then the communication of intelligent structures must obey the same logic.

The next section addresses this implication directly, examining the ethics of publication, openness, and legibility under the constraints established throughout the essay.

% --------------------------------------------------
\section{Publication, Openness, and Epistemic Responsibility}
% --------------------------------------------------

\subsection{From Internal Architecture to External Disclosure}

The preceding section characterizes general intelligence in terms of internal architecture: construction history, modularity, abstraction, refusal, and regulated transfer. These properties do not terminate at the boundary of the system. They extend outward into the system’s interactions with its environment, including how its structures are communicated, taught, or published.

Publication is itself a form of transfer. It transports constructions from one epistemic context into others, often far removed from the conditions under which they were formed. As such, publication is subject to the same constraints as action, inference, and reuse. To treat it as exempt is to introduce a structural inconsistency.

If intelligence depends on boundaries internally, then responsible disclosure must respect boundaries externally.

\subsection{Why Openness Is Not a Scalar Virtue}

Openness is frequently framed as a scalar good: more transparency is better, more access is better, more reproducibility is better. This framing collapses distinct kinds of interaction into a single dimension and ignores the role of scope.

Inspection, understanding, modification, and deployment are not interchangeable. They require different kinds of access and carry different risks. A system that permits inspection without permitting modification may remain coherent; a system that permits unrestricted modification may not.

Treating openness as unqualified obscures this distinction. It conflates the right to see with the right to act, and the ability to describe with the authority to apply.

\subsection{Effort-Gated Legibility}

One way to preserve this distinction without resorting to secrecy is through effort-gated legibility. An artifact is effort-gated when understanding it requires reconstructing the constraints that make it valid. The effort is not imposed artificially; it arises from the structure itself.

Formal definitions, cumulative dependencies, and non-operational descriptions serve this role. They allow scrutiny and critique while preventing immediate extraction. Nothing is hidden, but nothing is portable without discipline.

This approach mirrors the graded access observed in other domains. Reading source code does not grant permission to write to the kernel. Observing neural activity does not grant control over cognition. Understanding an abstraction does not automatically authorize its deployment.

\subsection{Why Recipes Are Categorically Different}

A recipe collapses architecture into procedure. It removes context, suppresses refusal, and presents transfer as unconditional. In doing so, it destroys the invariants that made the original construction coherent.

Publishing recipes for general intelligence is therefore not an act of openness but a category error. It invites reuse without scope, optimization without constraint, and deployment without responsibility.

By contrast, publishing architectures preserves structure while refusing extraction. It allows understanding to scale with effort and competence rather than with reach alone.

\subsection{Misuse as a Structural Failure}

Misuse is often framed as a moral failing of users rather than as a design failure of artifacts. While intent matters, this framing is incomplete. When misuse is predictable, it is structural.

An artifact that can be easily misapplied without reconstructing its constraints has already failed to enforce its own scope. Responsibility does not lie solely with the user; it lies with the absence of boundaries that would have prevented illegitimate transfer.

Effort-gated legibility addresses this failure by aligning access with competence.

\subsection{Refusal at the Level of Publication}

Just as intelligent systems must refuse illegitimate actions, authors and institutions must refuse illegitimate forms of disclosure. This refusal is not censorship. It is the preservation of coherence.

Refusal at the level of publication may take many forms: declining to provide stepwise instructions, delaying operational detail, emphasizing formal constraints over application, or requiring cumulative engagement. These are not evasions. They are boundary operators.

\subsection{The Ethics of Constraint Preservation}

The ethical stance that follows from this framework is neither maximal openness nor protective secrecy. It is constraint preservation. The primary obligation is not to maximize access, but to ensure that what is accessed remains meaningful and survivable under reuse.

This stance may appear conservative in environments that reward immediacy and portability. Yet it is precisely this conservatism that allows knowledge to accumulate rather than degrade.

% --------------------------------------------------
\section{Variational Formulation of General Intelligence}
% --------------------------------------------------

\subsection{State Variables and Configuration Space}

We model a general intelligence as a dynamical system evolving on a constrained configuration space rather than as a static computational artifact. The system is characterized by a set of generalized coordinates capturing coherence, action tendency, latent variation, and boundary structure.

Let the configuration at time $t$ be given by
\[
q(t) = \big( \Phi(t), \mathbf{v}(t), S(t), \pi(t), \mathcal{B}(t) \big),
\]
where:
\begin{itemize}
\item $\Phi(t)$ denotes a scalar coherence or abstraction density,
\item $\mathbf{v}(t)$ denotes a vector-valued policy flow or action tendency,
\item $S(t)$ denotes internal entropy or latent slack,
\item $\pi(t)$ denotes an internal policy distribution,
\item $\mathcal{B}(t)$ denotes boundary or scope structure mediating interaction.
\end{itemize}

These variables are not representations of the environment. They are intensities describing internal structure and admissible change.

The system evolves on a constrained manifold $\mathcal{M} \subset \mathcal{Q}$ determined by preserved invariants. Points outside $\mathcal{M}$ correspond to incoherent or illegitimate configurations.

\subsection{Action Principle}

The evolution of the system is determined by an action functional
\[
\mathcal{S}[q] = \int_{t_0}^{t_1} \mathcal{L}(q, \dot{q}) \, dt,
\]
where admissible trajectories are those that extremize $\mathcal{S}$ subject to the constraints defining $\mathcal{M}$.

General intelligence, on this account, is not defined by the ability to reach arbitrary configurations, but by the existence of stable low-action trajectories that preserve invariants under reuse and exposure.

\subsection{Lagrangian Structure}

We decompose the Lagrangian as
\[
\mathcal{L} = T - V - \Lambda + \Xi,
\]
where each term encodes a distinct structural requirement.

\subsubsection{Kinetic Term}

The kinetic term measures the capacity for change:
\[
T = \frac{1}{2} m_\Phi \dot{\Phi}^2
+ \frac{1}{2} m_v \|\dot{\mathbf{v}}\|^2
+ \frac{1}{2} m_\pi \|\dot{\pi}\|^2.
\]
These terms do not encode performance, but responsiveness: the system's ability to adapt its internal structure.

\subsubsection{Invariant Potential}

Invariant preservation is enforced by a potential term
\[
V = \alpha \, d(\Phi, \mathcal{I})^2
+ \beta \, d(\mathbf{v}, \mathcal{A}_{\mathrm{adm}})^2,
\]
where $\mathcal{I}$ denotes the invariant manifold associated with coherent abstraction, and $\mathcal{A}_{\mathrm{adm}}$ denotes the admissible action set.

Deviation from preserved invariants incurs increasing energetic cost. Illegitimate generalization corresponds to climbing the potential.

\subsubsection{Boundary and Legibility Penalty}

Boundary integrity is enforced by
\[
\Lambda = \gamma \, \|\nabla \mathcal{B}\|^2
+ \delta \, \kappa(\mathcal{B}, E),
\]
where $\kappa$ measures coupling to external observational or extractive fields $E$.

This term penalizes uncontrolled boundary collapse and excessive exposure. Interaction remains possible, but unregulated legibility is energetically disfavored.

\subsubsection{Learning and Compression Term}

Learning appears as constrained entropy descent:
\[
\Xi = - \eta \, \frac{d}{dt} \mathrm{KL}\!\left( \pi \,\|\, \pi_{\mathrm{comp}} \right),
\]
where $\pi_{\mathrm{comp}}$ denotes a compressed policy distribution preserving invariant behavior.

This term favors reorganization of internal structure that reduces description length without violating scope.

\subsection{Euler--Lagrange Dynamics}

Admissible trajectories satisfy the Euler--Lagrange equations
\[
\frac{d}{dt} \frac{\partial \mathcal{L}}{\partial \dot{q}_i}
- \frac{\partial \mathcal{L}}{\partial q_i} = 0,
\]
subject to the constraints defining $\mathcal{M}$.

Constraint forces arise naturally from the geometry of the configuration space and require no explicit safety rules.

\subsection{Hamiltonian Formulation}

Define conjugate momenta
\[
p_i = \frac{\partial \mathcal{L}}{\partial \dot{q}_i}.
\]
The Hamiltonian is given by
\[
\mathcal{H}(q,p) = \sum_i p_i \dot{q}_i - \mathcal{L}.
\]

In this formulation, refusal corresponds to regions of phase space where
\[
\mathcal{H} \to \infty.
\]
No admissible trajectory enters such regions. Refusal is therefore structural rather than procedural.

\subsection{Refusal as Forbidden Phase Space}

Configurations that violate invariants, collapse boundaries, or destroy replayable construction history lie outside $\mathcal{M}$ and are separated by divergent action.

The system does not evaluate these configurations and reject them. They are dynamically inaccessible.

This realizes refusal as a property of the action landscape rather than as an explicit decision.

\subsection{Interpretation}

Under this formulation, general intelligence is characterized by:
\begin{itemize}
\item stable low-action trajectories under reuse,
\item invariant-preserving abstraction as compression,
\item lawful transfer constrained by geometry,
\item refusal encoded as inaccessible phase space,
\item legibility regulated by boundary energetics.
\end{itemize}

No objective function is maximized. No global reward is assumed. Coherence is preserved by the structure of the dynamics itself.

% --------------------------------------------------
\section{Field-Theoretic Extension of the Variational Model}
% --------------------------------------------------

\subsection{Spatially Extended Intelligence Fields}

To model general intelligence as a distributed system rather than a point dynamical process, we extend the variational formulation to fields defined over a spatial domain $\Omega \subset \mathbb{R}^n$.

Let the system be described by fields
\[
\Phi(x,t), \quad \mathbf{v}(x,t), \quad S(x,t), \quad \pi(x,t), \quad \mathcal{B}(x,t),
\]
where $x \in \Omega$ indexes internal structure, memory locality, or semantic region.

The action functional becomes
\[
\mathcal{S} = \int dt \int_{\Omega}
\mathcal{L}\!\left(
\Phi, \partial_t \Phi, \nabla \Phi,
\mathbf{v}, \partial_t \mathbf{v}, \nabla \mathbf{v},
S, \pi, \mathcal{B}
\right)
\, dx.
\]

This formulation treats intelligence as a continuous medium whose coherence depends on the regulated propagation of structure.

\subsection{Field Lagrangian Density}

A representative Lagrangian density is given by
\begin{align*}
\mathcal{L} =
&\;\frac{1}{2} \rho_\Phi (\partial_t \Phi)^2
- \frac{1}{2} c_\Phi \|\nabla \Phi\|^2
\\
&+ \frac{1}{2} \rho_v \|\partial_t \mathbf{v}\|^2
- \frac{1}{2} c_v \|\nabla \mathbf{v}\|^2
\\
&- U(\Phi, \mathbf{v}, \mathcal{I})
- \Lambda(\mathcal{B}, \nabla \mathcal{B})
+ \Xi(\pi, S).
\end{align*}

Here:
\begin{itemize}
\item gradient penalties enforce smoothness and locality,
\item $U$ penalizes deviation from invariant manifolds,
\item $\Lambda$ enforces boundary integrity and limits information flux,
\item $\Xi$ encodes constrained entropy descent.
\end{itemize}

Sharp discontinuities correspond to boundary failure and incur unbounded action.

\subsection{Euler--Lagrange Field Equations}

The resulting field equations take the form
\[
\partial_t \left( \frac{\partial \mathcal{L}}{\partial (\partial_t \Phi)} \right)
- \nabla \cdot \left( \frac{\partial \mathcal{L}}{\partial (\nabla \Phi)} \right)
+ \frac{\partial \mathcal{L}}{\partial \Phi}
= 0,
\]
with analogous equations for $\mathbf{v}$ and the remaining fields.

Information, policy influence, and abstraction propagate as waves or diffusions only where permitted by boundary structure. Illegitimate propagation is dynamically suppressed.


% --------------------------------------------------
\section{Invariants and Conserved Quantities}
% --------------------------------------------------

\subsection{Symmetry and Constraint}

Invariant structure in the intelligence dynamics corresponds to symmetry of the action functional. Unlike physical symmetries of space and time, the relevant symmetries here act on abstraction, policy, and boundary variables.

Let $\mathcal{G}$ be a continuous group of transformations acting on the fields such that
\[
\mathcal{S}[q] = \mathcal{S}[g \cdot q]
\quad \forall g \in \mathcal{G}.
\]

These symmetries encode lawful reuse: transformations under which abstraction remains valid.

\subsection{Noether-Type Theorem}

\begin{theorem}[Invariant Preservation Theorem]
If the action $\mathcal{S}$ is invariant under a continuous group of transformations $\mathcal{G}$ acting on the configuration fields, then there exists a conserved quantity $J$ along all admissible trajectories.

Violation of the associated invariant corresponds to a breakdown of conservation and induces divergent action.
\end{theorem}

\subsection{Interpretation of Conserved Quantities}

The conserved quantities arising here are not physical momenta but structural measures, including:
\begin{itemize}
\item abstraction coherence flux,
\item policy consistency current,
\item boundary integrity charge.
\end{itemize}

Conservation expresses the fact that lawful transfer preserves structure. Attempts to reuse abstractions outside their symmetry class necessarily inject or dissipate conserved quantities and are therefore dynamically forbidden.

\subsection{Refusal as Symmetry Breaking}

Refusal corresponds to the absence of symmetry extension. When a proposed transformation lies outside $\mathcal{G}$, no conserved current exists, and the action becomes unbounded.

Thus refusal is not an exception to the dynamics; it is the absence of a symmetry under which motion could proceed.


% --------------------------------------------------
\section{CLIO Dynamics as a Slow--Fast Decomposition}
% --------------------------------------------------

\subsection{Separation of Timescales}

General intelligence requires simultaneous stability and adaptability. This is realized through a separation of timescales between fast policy dynamics and slow structural optimization.

Let:
\[
(\Phi, \mathcal{B}) \quad \text{evolve on a slow timescale},
\]
\[
(\mathbf{v}, \pi) \quad \text{evolve on a fast timescale}.
\]

This induces a foliation of phase space into slow manifolds parameterized by boundary and abstraction fields.

\subsection{Fast Policy Flow}

On short timescales, policy variables evolve according to
\[
\dot{\pi} = - \nabla_\pi \mathcal{H}_{\mathrm{fast}}(\pi \mid \Phi, \mathcal{B}),
\]
where $\mathcal{H}_{\mathrm{fast}}$ is the Hamiltonian restricted to fixed structural variables.

This corresponds to CLIO-style rapid inference and local policy adjustment.

\subsection{Slow Structural Evolution}

On longer timescales, abstraction and boundary fields evolve via
\[
\partial_t \Phi = - \epsilon \, \frac{\delta \mathcal{H}}{\delta \Phi},
\quad
\partial_t \mathcal{B} = - \epsilon \, \frac{\delta \mathcal{H}}{\delta \mathcal{B}},
\]
with $0 < \epsilon \ll 1$.

Structural change occurs only after repeated fast dynamics demonstrate invariant preservation or violation.

\subsection{Policy Refusal via Manifold Geometry}

Policies that require leaving the slow manifold correspond to directions of infinite curvature in the Hamiltonian landscape. These directions are dynamically inaccessible.

Refusal therefore appears as geometric obstruction: no slow-fast trajectory exists that preserves invariants.

\subsection{Interpretation}

CLIO emerges here not as an algorithm but as a dynamical regime:
\begin{itemize}
\item fast loops explore policy space locally,
\item slow loops reshape abstraction and boundary geometry,
\item only invariant-preserving couplings survive averaging.
\end{itemize}

This realizes intelligence as constrained exploration over time rather than immediate optimization.

% --------------------------------------------------
\section{Stability of Invariant-Preserving Dynamics}
% --------------------------------------------------

\subsection{Motivation}

A theory of general intelligence that emphasizes constraint, refusal, and boundary regulation must establish that such systems are not merely coherent but dynamically stable. Without stability, the architecture would describe a fragile ideal rather than a realizable regime.

Stability here does not mean convergence to a fixed point. It means persistence of coherent behavior under perturbation, reuse, and partial exposure.

\subsection{Invariant-Preserving Attractors}

Let $\mathcal{M} \subset \mathcal{Q}$ denote the manifold of admissible configurations preserving the system’s invariants. The Hamiltonian dynamics induce a flow $\varphi_t$ on $\mathcal{Q}$.

\begin{definition}
An \emph{invariant-preserving attractor} is a compact set $\mathcal{A} \subset \mathcal{M}$ such that:
\begin{enumerate}
\item trajectories starting in a neighborhood of $\mathcal{A}$ remain in $\mathcal{M}$ for all future time,
\item deviations transverse to $\mathcal{M}$ experience restoring forces induced by the invariant potential,
\item motion within $\mathcal{A}$ preserves the conserved quantities associated with the system’s symmetries.
\end{enumerate}
\end{definition}

Such attractors correspond to stable regimes of intelligent behavior rather than static solutions.

\subsection{Stability Theorem}

\begin{theorem}[Invariant Stability Theorem]
Assume the following conditions:
\begin{enumerate}
\item the invariant potential $V$ is coercive outside $\mathcal{M}$,
\item boundary penalties $\Lambda$ diverge under boundary collapse,
\item entropy descent $\Xi$ is bounded below,
\item slow--fast separation holds between policy and structural variables.
\end{enumerate}
Then the induced Hamiltonian flow admits invariant-preserving attractors $\mathcal{A} \subset \mathcal{M}$ that are Lyapunov-stable under admissible perturbations.
\end{theorem}

\subsection{Sketch of Argument}

Coercivity of $V$ ensures that trajectories leaving $\mathcal{M}$ incur unbounded energy cost, producing restoring forces normal to the manifold. Divergence of $\Lambda$ prevents collapse of boundary structure, eliminating destabilizing modes associated with unregulated coupling.

Bounded entropy descent ensures that learning does not induce runaway collapse of internal degrees of freedom. Slow--fast separation ensures that rapid policy fluctuations average out before structural variables evolve, yielding effective stability on long timescales.

Together, these conditions guarantee persistence of coherent trajectories without requiring global optimization or centralized control.

\subsection{Interpretation}

Stability is achieved not by suppressing change, but by constraining it. The system remains adaptive within $\mathcal{M}$ while being dynamically excluded from incoherent regimes.

This explains how intelligence can remain flexible without dissolving itself under generalization pressure.


% --------------------------------------------------
\section{Comparison to Existing Formalisms}
% --------------------------------------------------

\subsection{Relation to Variational Inference}

Variational inference frames intelligence as minimization of a divergence between internal models and external data. While formally similar in its use of variational principles, the present framework differs in its treatment of constraints.

In variational inference, constraints typically appear as regularizers. Here, constraints define the admissible manifold itself. Violations are not penalized softly; they are dynamically inaccessible.

As a result, refusal is structural rather than statistical, and generalization is lawful rather than approximate.

\subsection{Relation to the Free Energy Principle}

The Free Energy Principle (FEP) characterizes adaptive systems as minimizing variational free energy under a generative model. Markov blankets play a central role in mediating internal and external states.

The present framework agrees with the necessity of boundaries but diverges in emphasis. Boundaries are not introduced to support inference, but to preserve invariants under reuse. Entropy descent occurs only where it preserves abstraction coherence, not universally.

Where FEP emphasizes prediction, this framework emphasizes survivability of structure.

\subsection{Relation to Control-Theoretic AGI}

Control-theoretic approaches typically assume a predefined objective or reward function. Intelligence is identified with optimal control under uncertainty.

In contrast, the present framework does not assume a global objective. It replaces optimality with admissibility. Actions are selected not because they maximize reward, but because they preserve coherence.

Refusal emerges naturally where no admissible control exists.

\subsection{Relation to Foundation Model Paradigms}

Large foundation models emphasize scale, transfer, and emergent capability through parameterization. Their success depends on weak constraints and broad generalization.

The present framework explains both their power and their fragility. In the absence of strong boundary enforcement, generalization proceeds by collapse of invariants rather than by lawful transfer. Stability must be imposed externally rather than emerging from dynamics.

This comparison is descriptive rather than critical. It identifies structural differences rather than proposing replacements.

\subsection{Summary of Distinctions}

Across these comparisons, the distinguishing features of the present framework are:
\begin{itemize}
\item invariants as first-class objects,
\item refusal as phase-space exclusion,
\item boundaries as dynamical fields,
\item generality as symmetry-preserving transfer,
\item stability through constraint rather than optimization.
\end{itemize}

These features are not additional mechanisms. They are consequences of treating intelligence as a constrained dynamical system rather than as an objective-maximizing machine.

\subsection{Final Thoughts}

The argument has now come full circle. Beginning from the primacy of events and construction history, it has developed a view of intelligence as boundary-regulated adaptation. The same principles that govern cells, brains, and operating systems govern ideas and their dissemination.

In the concluding section, these threads are drawn together to restate the central claim: intelligence that cannot regulate its own boundaries, internally or externally, does not remain intelligent for long.

% --------------------------------------------------
\section{Intelligence That Persists Regulates Itself}
% --------------------------------------------------

The argument of this essay has proceeded by constraint rather than by accumulation. Beginning from the primacy of events over states, it has treated intelligence as an irreversible process of construction whose coherence depends on the preservation of invariants under reuse. Abstraction has been redefined as invariant-preserving compression; modularity as an ontological condition rather than an engineering convenience; refusal as a constitutive operation rather than a failure mode; and generality as lawful transfer rather than breadth of application.

From these commitments, the necessity of boundaries has followed without appeal to external ethics or precautionary principles. Semi-permeable boundaries appear wherever adaptive systems persist: in biological membranes, neural synchronization, evolutionary buffering, computational privilege separation, and epistemic practice. These boundaries regulate interaction, preserve gradients, and prevent collapse under exposure. They are not obstacles to intelligence. They are its enabling conditions.

Legibility, viewed through this lens, is no longer an unqualified good. It is a form of exposure that alters the environment in which intelligence operates. Unregulated legibility selects for portability over robustness, extraction over coherence, and immediacy over survivability. Intelligence that cannot regulate its own visibility becomes a target of its own success.

This does not license secrecy, obscurantism, or authority-based restriction. On the contrary, the framework developed here distinguishes sharply between concealment and constraint. Inspection without modification, understanding without authorization, and critique without deployment are not limitations on openness; they are its disciplined forms. Effort-gated legibility preserves falsifiability while preventing illegitimate reuse.

The architectural characterization of general intelligence that emerges is therefore conservative by design. It privileges coherence over coverage, refusal over indiscriminate action, and cumulative understanding over extractable technique. Such conservatism is often mistaken for timidity. In fact, it is what allows intelligence to scale without dissolving itself.

A final analogy may serve to close the loop. An operating system that grants all processes root access does not become more powerful; it becomes unstable. A nervous system that synchronizes all regions at once does not become more intelligent; it seizes. A genome without buffering cannot evolve. An epistemic system without boundaries cannot accumulate knowledge.

The same is true of intelligence itself.

Systems that cannot refuse do not remain general.  
Systems that cannot regulate their own legibility do not remain coherent.  
Systems that cannot preserve their invariants under reuse do not remain intelligent.

What persists is not maximal capability, but disciplined construction under constraint.

% --------------------------------------------------
\section{Conclusion}
% --------------------------------------------------

This work has developed a structural theory of general intelligence grounded in constrained dynamics rather than task performance or objective maximization. Intelligence has been treated as an irreversible process of construction whose persistence depends on the preservation of invariants under reuse, transfer, and exposure.

Beginning from the primacy of events over states, the analysis established that adaptive systems require semi-permeable boundaries to regulate interaction. These boundaries arise not as safeguards but as necessary conditions for maintaining coherence. Refusal was shown to be a structural property of such systems, corresponding to the non-existence of admissible transformations rather than to error or intervention.

A variational formulation was introduced to formalize these principles. Within this framework, abstraction appears as invariant-preserving compression, learning as constrained entropy descent, and generality as lawful transfer along symmetry-preserving directions. Boundary structure was incorporated directly into the action, making illegitimate configurations dynamically inaccessible.

Extending the model to a field-theoretic setting demonstrated how intelligence can be distributed across space or semantic domains while preserving locality and coherence. Conserved quantities associated with invariants were derived via symmetry considerations, establishing a Noether-type correspondence between lawful reuse and structural conservation.

The resulting dynamics admit stable invariant-preserving attractors under mild conditions. Stability is achieved not through global optimization or centralized control, but through the geometry of the admissible manifold and the energetic cost of boundary violation. Fast policy dynamics and slow structural evolution were shown to coexist via a natural separation of timescales, yielding adaptive behavior without collapse.

Comparison to existing formalisms clarified the distinctiveness of this approach. Unlike optimization-centric or inference-based models, the present framework treats refusal, boundary regulation, and invariant preservation as foundational rather than auxiliary. Capability is constrained by coherence, not expanded at its expense.

Taken together, these results support a conception of general intelligence as a physically realizable regime of constrained dynamics. Such systems remain adaptive because they cannot act, infer, or disclose beyond what their structure permits. Generality emerges not from breadth alone, but from the disciplined preservation of invariants across change.

This view suggests that intelligence, in any substrate, persists only where boundaries are maintained, refusal is enforced by geometry, and learning proceeds through lawful compression rather than unconstrained optimization.

% --------------------------------------------------
% Appendices: Mathematical Formalisms
% --------------------------------------------------
\appendix

% --------------------------------------------------
\section{Configuration Manifolds, Constraints, and Refusal}
% --------------------------------------------------

\newcommand{\Q}{\mathcal{Q}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\Aadm}{\mathcal{A}_{\mathrm{adm}}}
\newcommand{\Ham}{\mathcal{H}}
\newcommand{\Lag}{\mathcal{L}}
\newcommand{\Act}{\mathcal{S}}
\newcommand{\Bnd}{\mathcal{B}}

\begin{definition}[Configuration manifold]
Let $\Q$ be a smooth finite-dimensional manifold (or Fr\'echet manifold in the field case) with local coordinates
\[
q = (\Phi, \mathbf{v}, S, \pi, \Bnd).
\]
\end{definition}

\begin{definition}[Invariant constraints and admissible manifold]
Let $F:\Q \to \mathbb{R}^k$ be smooth and define the admissible manifold
\[
\M := F^{-1}(0).
\]
Assume $0$ is a regular value of $F$, so $\M$ is an embedded submanifold with tangent space
\[
T_q \M = \ker DF(q).
\]
\end{definition}

\begin{definition}[Admissible variations]
A variation $\delta q(t)$ along a curve $q(t)\in \M$ is admissible if
\[
DF(q(t))\,\delta q(t)=0 \quad \text{for all } t.
\]
\end{definition}

\begin{definition}[Refusal set]
Let $\Ham:\,T^*\Q \to \mathbb{R}\cup\{+\infty\}$. Define the refusal set
\[
\mathcal{R} := \{(q,p)\in T^*\Q:\ \Ham(q,p)=+\infty\}.
\]
A state is refused iff it lies in $\mathcal{R}$.
\end{definition}

\begin{lemma}[Normal coercivity implies manifold confinement]
Assume there exists a neighborhood $U$ of $\M$ and constants $c_1,c_2>0$ such that
\[
V(q)\ \ge\ c_1\,\mathrm{dist}(q,\M)^2 - c_2 \quad \text{for all } q\in U,
\]
and that $\Ham$ satisfies $\Ham(q,p)\ge V(q)$ on $T^*U$.
Then for any energy sublevel set
\[
\Sigma_E:=\{(q,p)\in T^*U:\ \Ham(q,p)\le E\},
\]
there exists $r(E)>0$ such that $\Sigma_E \subset \{(q,p): \mathrm{dist}(q,\M)\le r(E)\}$.
\end{lemma}

\begin{proof}
For $(q,p)\in \Sigma_E$, one has $E\ge \Ham(q,p)\ge V(q)\ge c_1\mathrm{dist}(q,\M)^2-c_2$, hence
$\mathrm{dist}(q,\M)^2\le (E+c_2)/c_1$. Take $r(E)=\sqrt{(E+c_2)/c_1}$.
\end{proof}

% --------------------------------------------------
\section{Field-Theoretic Euler--Lagrange Equations}
% --------------------------------------------------

\newcommand{\Om}{\Omega}

\begin{definition}[Field configuration space]
Let $\Om\subset \mathbb{R}^n$ be a bounded domain with smooth boundary.
Let the field variables be
\[
\Phi:\Om\times\mathbb{R}\to\mathbb{R},\quad
\mathbf{v}:\Om\times\mathbb{R}\to\mathbb{R}^n,\quad
S:\Om\times\mathbb{R}\to\mathbb{R},\quad
\pi:\Om\times\mathbb{R}\to\Delta,\quad
\Bnd:\Om\times\mathbb{R}\to \mathbb{R}^m,
\]
where $\Delta$ is a (finite-dimensional) simplex or a suitable function space.
\end{definition}

\begin{definition}[Action functional]
Let $\Lag$ be a Lagrangian density depending smoothly on $(q,\partial_t q,\nabla q)$.
Define
\[
\Act[q]=\int_{t_0}^{t_1}\int_{\Om} \Lag(q,\partial_t q,\nabla q)\,dx\,dt.
\]
\end{definition}

\begin{theorem}[Euler--Lagrange field equations]
Assume variations $\delta q$ vanish on $\partial \Om\times [t_0,t_1]$ and at times $t_0,t_1$.
Then a stationary point of $\Act$ satisfies, componentwise for each field $q^\alpha$,
\[
\partial_t\!\left(\frac{\partial \Lag}{\partial(\partial_t q^\alpha)}\right)
+\sum_{i=1}^n \partial_{x_i}\!\left(\frac{\partial \Lag}{\partial(\partial_{x_i} q^\alpha)}\right)
-\frac{\partial \Lag}{\partial q^\alpha} \;=\; 0.
\]
\end{theorem}

\begin{proof}
Compute the first variation:
\[
\delta \Act=\int\!\!\int \left(
\frac{\partial \Lag}{\partial q^\alpha}\delta q^\alpha
+\frac{\partial \Lag}{\partial(\partial_t q^\alpha)}\partial_t(\delta q^\alpha)
+\frac{\partial \Lag}{\partial(\partial_{x_i} q^\alpha)}\partial_{x_i}(\delta q^\alpha)
\right)\,dx\,dt,
\]
(sum over $\alpha$ and $i$). Integrate by parts in $t$ and $x_i$ and use boundary/endpoint vanishing to remove boundary terms:
\[
\delta \Act=\int\!\!\int \left(
\frac{\partial \Lag}{\partial q^\alpha}
-\partial_t\!\left(\frac{\partial \Lag}{\partial(\partial_t q^\alpha)}\right)
-\partial_{x_i}\!\left(\frac{\partial \Lag}{\partial(\partial_{x_i} q^\alpha)}\right)
\right)\delta q^\alpha\,dx\,dt.
\]
Since $\delta q^\alpha$ are arbitrary, the coefficient must vanish.
\end{proof}

% --------------------------------------------------
\section{Hamiltonian Structure and Refusal Barriers}
% --------------------------------------------------

\begin{definition}[Legendre transform]
Let $\Lag(q,\dot q)$ be $C^2$ and strictly convex in $\dot q$.
Define momenta $p_i=\partial \Lag/\partial \dot q_i$ and Hamiltonian
\[
\Ham(q,p)=\sup_{\dot q}\left(\sum_i p_i\dot q_i-\Lag(q,\dot q)\right).
\]
\end{definition}

\begin{theorem}[Hamilton's equations]
If $\Ham$ is finite and $C^2$ on an open set $U\subset T^*\Q$, then the induced flow satisfies
\[
\dot q_i=\frac{\partial \Ham}{\partial p_i},\qquad
\dot p_i=-\frac{\partial \Ham}{\partial q_i}.
\]
\end{theorem}

\begin{proof}
On $U$, strict convexity gives the smooth inverse $\dot q=\dot q(q,p)$.
Then $\Ham(q,p)=p\cdot \dot q-\Lag(q,\dot q)$.
Differentiate:
\[
d\Ham=\dot q\cdot dp + p\cdot d\dot q - \frac{\partial \Lag}{\partial q}\cdot dq
-\frac{\partial \Lag}{\partial \dot q}\cdot d\dot q
=\dot q\cdot dp - \frac{\partial \Lag}{\partial q}\cdot dq,
\]
since $p=\partial \Lag/\partial \dot q$ cancels the $d\dot q$ terms.
Thus $\partial \Ham/\partial p=\dot q$ and $\partial \Ham/\partial q=-\partial \Lag/\partial q$.
With Euler--Lagrange $d/dt(\partial \Lag/\partial \dot q)=\partial \Lag/\partial q$ we obtain $\dot p=-\partial \Ham/\partial q$.
\end{proof}

\begin{lemma}[Infinite barrier is forward-invariant]
Let $\Ham$ be lower semicontinuous and define $\mathcal{R}=\{\Ham=+\infty\}$.
If a trajectory $(q(t),p(t))$ satisfies $\Ham(q(t),p(t))<\infty$ for some $t=t_\ast$ and energy is conserved on $\{\Ham<\infty\}$, then $(q(t),p(t))\notin \mathcal{R}$ for all $t$ in its maximal interval of existence.
\end{lemma}

\begin{proof}
Energy conservation gives $\Ham(q(t),p(t))=\Ham(q(t_\ast),p(t_\ast))<\infty$ whenever the solution remains in $\{\Ham<\infty\}$. If it entered $\mathcal{R}$ at some time, $\Ham$ would be $+\infty$, contradicting conservation.
\end{proof}

% --------------------------------------------------
\section{Noether Currents for Field Symmetries}
% --------------------------------------------------

\begin{definition}[Infinitesimal symmetry]
Let $q^\alpha$ be fields and $\Lag(q,\partial_\mu q)$ with $\mu=0,\dots,n$ ($x^0=t$).
An infinitesimal symmetry is a variation
\[
\delta q^\alpha = \varepsilon\, X^\alpha(q,x)
\]
such that the induced Lagrangian variation is a total divergence:
\[
\delta \Lag = \varepsilon\,\partial_\mu K^\mu
\]
for some $K^\mu$.
\end{definition}

\begin{theorem}[Noether current]
Assume $q$ satisfies the Euler--Lagrange equations.
Then the current
\[
J^\mu \;=\; \frac{\partial \Lag}{\partial(\partial_\mu q^\alpha)}\,X^\alpha \;-\; K^\mu
\]
is conserved:
\[
\partial_\mu J^\mu = 0.
\]
\end{theorem}

\begin{proof}
Compute
\[
\delta \Lag
= \frac{\partial \Lag}{\partial q^\alpha}\delta q^\alpha
+ \frac{\partial \Lag}{\partial(\partial_\mu q^\alpha)}\partial_\mu(\delta q^\alpha).
\]
Rewrite the second term:
\[
\frac{\partial \Lag}{\partial(\partial_\mu q^\alpha)}\partial_\mu(\delta q^\alpha)
= \partial_\mu\!\left(\frac{\partial \Lag}{\partial(\partial_\mu q^\alpha)}\delta q^\alpha\right)
- \partial_\mu\!\left(\frac{\partial \Lag}{\partial(\partial_\mu q^\alpha)}\right)\delta q^\alpha.
\]
Hence
\[
\delta \Lag
= \left(\frac{\partial \Lag}{\partial q^\alpha}
-\partial_\mu\!\left(\frac{\partial \Lag}{\partial(\partial_\mu q^\alpha)}\right)\right)\delta q^\alpha
+ \partial_\mu\!\left(\frac{\partial \Lag}{\partial(\partial_\mu q^\alpha)}\delta q^\alpha\right).
\]
On-shell the Euler--Lagrange bracket vanishes, so
\[
\delta \Lag = \partial_\mu\!\left(\frac{\partial \Lag}{\partial(\partial_\mu q^\alpha)}\delta q^\alpha\right).
\]
By symmetry, $\delta \Lag=\partial_\mu K^\mu$, therefore
\[
\partial_\mu\!\left(\frac{\partial \Lag}{\partial(\partial_\mu q^\alpha)}\delta q^\alpha - K^\mu\right)=0.
\]
Divide by $\varepsilon$ and substitute $\delta q^\alpha=\varepsilon X^\alpha$.
\end{proof}

% --------------------------------------------------
\section{Slow--Fast Decomposition and CLIO Regimes}
% --------------------------------------------------

\newcommand{\eps}{\varepsilon}

\begin{definition}[Slow--fast Hamiltonian system]
Let $(x,y)\in \mathbb{R}^m\times \mathbb{R}^\ell$ with $0<\eps\ll 1$ and Hamiltonian
\[
\Ham_\eps(x,y,p_x,p_y)=\Ham_0(x,p_x)\;+\;\Ham_{\mathrm{fast}}(x,y,p_y)\;+\;\eps\,\Ham_1(x,y,p_x,p_y),
\]
with canonical symplectic form $\omega=dx\wedge dp_x + dy\wedge dp_y$.
\end{definition}

\begin{definition}[Critical manifold]
Assume for each fixed $(x,p_x)$ the fast subsystem has an equilibrium set
\[
\mathcal{C}_0 := \{(x,y,p_x,p_y):\ \partial_{y}\Ham_{\mathrm{fast}}=0,\ \partial_{p_y}\Ham_{\mathrm{fast}}=0\}.
\]
\end{definition}

\begin{theorem}[Persistence of normally hyperbolic slow manifolds (Fenichel-type)]
Assume $\mathcal{C}_0$ is a compact normally hyperbolic invariant manifold for the $\eps=0$ fast flow and that $\Ham_\eps$ is $C^r$, $r\ge 2$.
Then for sufficiently small $\eps>0$ there exists a locally invariant manifold $\mathcal{C}_\eps$ $C^{r-1}$-close to $\mathcal{C}_0$ and the reduced flow on $\mathcal{C}_\eps$ is $C^{r-1}$ conjugate to the slow drift induced by $\Ham_0+\eps\Ham_1$.
\end{theorem}

\begin{proof}
Standard Fenichel theory for normally hyperbolic invariant manifolds applies to the fast-slow vector field generated by $\Ham_\eps$. Normal hyperbolicity provides exponential contraction/expansion transverse to $\mathcal{C}_0$, yielding persistence and smoothness of $\mathcal{C}_\eps$ for small $\eps$ and conjugacy of reduced dynamics.
\end{proof}

\begin{lemma}[Geometric refusal via infinite curvature]
Let $\Ham$ be $C^2$ on an open set $U\subset T^*\Q$ and extend $\Ham$ by $+\infty$ outside $U$.
If a direction $\xi$ at $(q,p)\in U$ approaches $\partial U$ such that $\Ham(q+\tau\xi_q,p+\tau\xi_p)\to+\infty$ as $\tau\uparrow\tau_\ast$, then no finite-energy trajectory can cross $\partial U$ along $\xi$.
\end{lemma}

\begin{proof}
Along any finite-energy trajectory, $\Ham$ is conserved and finite. Approaching $\partial U$ along $\xi$ forces $\Ham\to+\infty$, contradicting conservation. Hence crossing is impossible.
\end{proof}

% --------------------------------------------------
\section{Lyapunov Stability for Invariant-Preserving Attractors}
% --------------------------------------------------

\newcommand{\Aset}{\mathcal{A}}

\begin{definition}[Lyapunov function]
A continuous function $W:U\to \mathbb{R}_{\ge 0}$ on a neighborhood $U$ of a compact set $\Aset$ is a Lyapunov function if:
\[
W^{-1}(0)=\Aset,\qquad \dot W \le 0 \text{ along trajectories in } U.
\]
\end{definition}

\begin{theorem}[Lyapunov stability from coercive invariant potentials]
Let $\Ham=T+V+\Lambda-\Xi$ on $T^*\Q$, with $T\ge 0$, $\Xi$ bounded above, and suppose there exists a compact $\Aset\subset \M$ and constants $c,C>0$ such that in a neighborhood $U$ of $\Aset$:
\[
V(q)+\Lambda(q)\ \ge\ c\,\mathrm{dist}(q,\M)^2,
\qquad
V(q)+\Lambda(q)\ \to +\infty \text{ as } q\to \partial U.
\]
Then $\Aset$ is Lyapunov-stable for the Hamiltonian flow restricted to the energy sublevel set $\{\Ham\le E\}$ for any $E$ with $\Aset\subset\{\Ham\le E\}\subset U$.
\end{theorem}

\begin{proof}
Fix such $E$ and define $W(q,p)=V(q)+\Lambda(q)$ on $\{\Ham\le E\}$.
Energy conservation implies trajectories remain in $\{\Ham\le E\}\subset U$.
By the lower bound, $W$ controls $\mathrm{dist}(q,\M)^2$.
Since $\Aset\subset \M$, $W=0$ on $\Aset$ and $W>0$ off $\M$.
Let $\epsilon>0$ be given. Choose $\delta>0$ such that $W<\delta \Rightarrow \mathrm{dist}(q,\M)<\epsilon$.
If initial data satisfy $W(q(0),p(0))<\delta$, then by energy confinement and the barrier condition at $\partial U$, the trajectory cannot exit the set $\{W<\delta'\}$ for a sufficiently small $\delta'\ge \delta$ contained in $U$, hence $\mathrm{dist}(q(t),\M)<\epsilon$ for all $t$.
\end{proof}

\printbibliography

\end{document}
