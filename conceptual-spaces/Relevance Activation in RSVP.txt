Relevance Activation Theory in the RSVP Framework:
A Derived Field-Theoretic Model of Cognition
June 26, 2025
Abstract
This paper presents a field-theoretic model of cognition, integrating Relevance Activation
Theory (RAT) within the Relativistic Scalar Vector Plenum (RSVP) framework. Cognition
is modeled as recursive associative trajectories through a derived semantic manifold M, gov-
erned by a scalar potential Φ, vector flow ⃗v, and entropy density S. These fields evolve accord-
ing to coupled differential equations, with relevance defined as vector alignment ⃗v · ∇Φ. The
framework generalizes predictive processing, global workspace theory, and embodied cogni-
tion, while providing diagnostic metrics (e.g., semantic torsion, entropy descent) for reasoning
failures in large reasoning models (LRMs). We formalize the dynamics, geometry, and neu-
rocognitive mappings, proposing empirical and computational pathways for validation.
1
Introduction
Recent empirical findings (e.g., [?]) reveal that large reasoning models (LRMs) often produce
shallow outputs under high-complexity conditions, suggesting that chain-based reasoning is lo-
cally plausible but globally brittle. We propose a novel model of cognition that reframes rea-
soning as recursive vectorial descent through a semantic field. Relevance Activation Theory
(RAT) posits that cognition involves feedback-mediated alignment of latent semantic cues with
internal goals, formalized as vector flows on a derived manifold. The Relativistic Scalar Vec-
tor Plenum (RSVP) provides a geometric and thermodynamic substrate, modeling cognition as
trajectories governed by scalar potential Φ, vector flow ⃗v, and entropy S. This paper formalizes
the RSVP-RAT framework, addressing its mathematical structure, neurocognitive mappings, and
implications for cognitive science and artificial intelligence.
2
Relevance Activation Theory
RAT conceptualizes cognition as a control system over semantic affordances, where relevance
is dynamically activated through feedback between internal reference signals and perceptual
inputs. For a semantic manifold M, relevance is defined as:
R(x) = ⃗v(x) · ∇Φ(x),
where ⃗v is the vector flow, ∇Φ is the gradient of the scalar potential, and x ∈M. Cognitive
trajectories γ(t) ⊂M evolve according to:
dγ
dt = ⃗v(γ(t)) −λ∇S(γ(t)),
where λ modulates entropy-based correction, ensuring recursive descent toward high-relevance,
low-entropy configurations.
3
RSVP Field Framework
The RSVP framework models cognition as the evolution of three coupled fields on a Lorentzian
manifold (M, g):
1

• Φ : M × R →R, a scalar potential encoding value or goal alignment.
• ⃗v : M × R →TM, a vector field encoding semantic flow or agency.
• S : M × R →R≥0, an entropy density encoding uncertainty or cognitive load.
The fields obey coupled evolution equations:
∂tΦ + ⃗v · ∇Φ = −δS,
∂t⃗v + (⃗v · ∇)⃗v = −∇Φ + η∇S + τ(γ),
∂tS + ∇· (S⃗v) = σ(Φ,⃗v),
where δ, η are dissipation coefficients, τ(γ) is semantic torsion, and σ captures entropy genera-
tion. The Lagrangian governing these dynamics is:
L = 1
2∥⃗v∥2 −Φ −δS + η⟨⃗v, ∇Φ⟩.
4
Semantic Manifold M
The manifold M is a differentiable stack Map(C, X), where C is a sensorimotor configuration
space and X encodes conceptual affordances. Its Riemannian metric gM is induced by seman-
tic similarity, with curvature Rl
ijk reflecting conceptual clustering. The dimensionality is de-
termined by the effective rank of the Jacobian Jf : Rninput →M. Dynamic patching (e.g., via
TARTAN-like tiling) allows M to adapt during learning or reasoning.
5
Neurocognitive Mappings
The fields map to neurobiological substrates:
• Φ: Dopaminergic reward signals or vmPFC BOLD activity, modeled as:
∂tΦ = DΦ∆Φ + freward(x, t).
• ⃗v: Phase-coupled oscillations or neural vector fields, quantifiable via MEG/EEG phase-locking
values.
• S: Neural entropy, computed as Shannon entropy of population codes or transformer soft-
max outputs.
6
Recursive Associative Trajectories
Cognitive processes are modeled as recursive associative trajectories γ(t) ⊂M, governed by:
dγ
dt = ⃗v(γ(t)) −λ∇S(γ(t)).
Semantic torsion is defined as:
τ(γ) = ∥⃗v ∧∇Φ∥+ ∥∇S · ⃗v∥.
These trajectories explain phenomena such as:
• Insight: Rapid torsion resolution (τ →0) with entropy drop (∆S < 0).
• Confusion: Stagnation in high-torsion regions (τ ≫0, ∇Φ ≈0).
• Shortcutting: Geodesic projection in flat regions of M (ker(∇Φ)).
2

7
Contrast with Large Reasoning Models
LRMs fail in high-complexity tasks due to:
• Shallow Φ minima, leading to premature convergence.
• Flat ∇S, indicating lack of entropic resolution.
• Misalignment ⃗v ⊥∇Φ, reflecting semantic drift.
Diagnostic invariants include:
• Alignment functional: A =
∫
γ
⃗v·∇Φ
∥⃗v∥∥∇Φ∥dt.
• Entropy descent rate: E = d
dtS(γ(t)).
8
Relation to Cognitive Theories
RSVP-RAT generalizes existing theories:
• Predictive Processing: ⃗v ∼−∇S embeds free-energy minimization.
• Global Workspace Theory: Low-S states correspond to broadcast trajectories.
• Embodied Cognition: Fields extend over sensorimotor manifolds Mbody ⊂M.
9
Future Work
Future research will:
• Simulate RSVP dynamics using neural field models (e.g., in NEST or Brian2).
• Test field mappings using fMRI/EEG during insight or multitasking tasks.
• Develop TARTAN, a platform for dynamic manifold patching and trajectory simulation.
• Explore BV-BRST quantization for symbolic-to-geometric transitions.
10
Conclusion
RSVP-RAT reframes cognition as recursive descent through a derived semantic field, offering
a geometric and thermodynamic alternative to symbolic or token-based models. By modeling
reasoning as trajectories governed by Φ, ⃗v, and S, the framework captures the dynamic, adaptive
nature of thought, providing a foundation for cognitive science and next-generation AI.
3

