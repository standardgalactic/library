1
00:00:00,160 --> 00:00:00,720
Bienvenidos.

2
00:00:00,980 --> 00:00:04,340
Hoy nos vamos a meter con una idea que, de entrada,

3
00:00:04,720 --> 00:00:06,160
suena completamente al revés.

4
00:00:06,740 --> 00:00:10,740
¿Puede algo ser increíblemente complejo sin ser en realidad

5
00:00:10,740 --> 00:00:11,840
inteligente?

6
00:00:12,260 --> 00:00:14,000
Siempre pensamos que van de la mano.

7
00:00:14,340 --> 00:00:17,360
Un sistema complejo, como, no sé, el cerebro humano,

8
00:00:17,720 --> 00:00:19,420
es el pináculo de la inteligencia.

9
00:00:19,800 --> 00:00:21,020
Pero, ¿y si no es así?

10
00:00:21,360 --> 00:00:23,820
Es que esa es la intuición que tenemos todos.

11
00:00:24,300 --> 00:00:27,820
Más complejo es igual a más inteligente, punto.

12
00:00:27,820 --> 00:00:30,840
Pero el material que tenemos hoy sobre la mesa,

13
00:00:31,140 --> 00:00:33,220
un artículo de investigación llamado

14
00:00:33,220 --> 00:00:35,540
Complejidad sin Inteligencia,

15
00:00:35,940 --> 00:00:38,300
le da la vuelta por completo a esa idea.

16
00:00:38,940 --> 00:00:41,380
Es casi como si nos dijera que, bueno,

17
00:00:41,880 --> 00:00:45,200
hemos estado midiendo las cosas con la regla equivocada.

18
00:00:45,520 --> 00:00:46,040
Justamente.

19
00:00:46,520 --> 00:00:49,700
Así que, la misión de hoy es entender este argumento.

20
00:00:50,220 --> 00:00:53,480
Nos proponen una forma distinta de ver la complejidad de

21
00:00:53,480 --> 00:00:56,720
cualquier cosa, desde una hormiga hasta un robot de última

22
00:00:56,720 --> 00:01:01,000
generación y la clave no está en su capacidad para pensar o para

23
00:01:01,000 --> 00:01:05,680
aprender, sino en la riqueza, en la organización de todo lo que

24
00:01:05,680 --> 00:01:07,460
puede hacer en este preciso instante.

25
00:01:08,040 --> 00:01:11,680
Es una idea que, la verdad, me genera muchísima curiosidad.

26
00:01:12,180 --> 00:01:15,880
Porque nos obliga a dejar de mirar hacia adentro, o sea,

27
00:01:16,140 --> 00:01:19,320
a los supuestos cálculos del cerebro o del procesador,

28
00:01:19,720 --> 00:01:22,740
y empezar a mirar hacia fuera, a la acción,

29
00:01:22,740 --> 00:01:24,880
a la relación con el mundo.

30
00:01:25,560 --> 00:01:29,500
La propuesta es que la complejidad no es un logro mental,

31
00:01:29,620 --> 00:01:33,660
digamos, sino una propiedad de la danza que baila una gente

32
00:01:33,660 --> 00:01:34,560
con su entorno.

33
00:01:35,000 --> 00:01:37,280
Y eso, pues, lo cambia todo.

34
00:01:38,080 --> 00:01:38,480
De acuerdo.

35
00:01:39,100 --> 00:01:40,780
Empecemos a desempacar esa danza.

36
00:01:41,420 --> 00:01:44,460
El documento se basa en un concepto que llama affordances,

37
00:01:44,880 --> 00:01:47,980
o, para que nos entendamos, posibilidades de acción.

38
00:01:48,380 --> 00:01:49,620
¿A qué se refiere exactamente?

39
00:01:49,620 --> 00:01:53,900
Mira, imagina que estás frente a una puerta con un picaporte.

40
00:01:54,460 --> 00:01:59,000
No necesitas pensar, eso es un objeto cilíndrico que puedo rotar

41
00:01:59,000 --> 00:02:00,340
para liberar un pestillo.

42
00:02:00,700 --> 00:02:03,640
No, simplemente ves la posibilidad de girarlo.

43
00:02:04,260 --> 00:02:07,360
El picaporte te ofrece o te permite esa acción.

44
00:02:07,820 --> 00:02:09,100
Esas son las affordances.

45
00:02:09,240 --> 00:02:09,880
Ah, ya.

46
00:02:10,420 --> 00:02:13,660
Son las acciones que el entorno pone a tu disposición,

47
00:02:13,920 --> 00:02:15,160
dadas tus capacidades.

48
00:02:15,160 --> 00:02:17,920
Una silla te ofrece sentarte.

49
00:02:18,360 --> 00:02:20,000
Un vaso te ofrece beber.

50
00:02:20,220 --> 00:02:20,680
Entiendo.

51
00:02:21,020 --> 00:02:24,080
Son como las invitaciones a la acción que nos hace el mundo.

52
00:02:24,860 --> 00:02:28,580
Y el artículo dice que la complejidad se mide por el conjunto

53
00:02:28,580 --> 00:02:32,680
de estas invitaciones que un agente puede aceptar ahora mismo.

54
00:02:32,820 --> 00:02:34,200
Ahí está la clave.

55
00:02:34,820 --> 00:02:36,320
En el ahora mismo.

56
00:02:36,320 --> 00:02:41,680
El término técnico que usan es que es una propiedad sincrónica.

57
00:02:42,400 --> 00:02:45,200
Pensemos en la caja de herramientas de un carpintero.

58
00:02:45,780 --> 00:02:50,880
La complejidad sincrónica no se preocupa de cómo aprendió a usar el martillo

59
00:02:50,880 --> 00:02:54,000
o si mañana aprenderá a usar una sierra nueva.

60
00:02:54,780 --> 00:02:57,820
Solo mira las herramientas que tiene en la caja hoy

61
00:02:57,820 --> 00:03:03,260
y la cantidad de cosas que puede construir con ellas en este preciso momento.

62
00:03:03,620 --> 00:03:05,020
Su repertorio actual.

63
00:03:05,020 --> 00:03:08,580
Pero, a ver, eso suena un poco limitante.

64
00:03:09,120 --> 00:03:11,960
No estamos ignorando la parte más importante,

65
00:03:12,420 --> 00:03:15,140
que es la capacidad de adaptarse y aprender.

66
00:03:15,840 --> 00:03:19,780
Un sistema que no aprende, por muy variado que sea su repertorio actual,

67
00:03:20,220 --> 00:03:21,900
parece un sistema frágil, ¿no?

68
00:03:22,100 --> 00:03:24,280
Es una objeción muy natural, sí.

69
00:03:24,820 --> 00:03:28,140
Pero el artículo nos pide que, por un momento,

70
00:03:28,700 --> 00:03:30,300
separemos los conceptos.

71
00:03:30,300 --> 00:03:33,900
No dice que el aprendizaje no sea importante,

72
00:03:34,340 --> 00:03:37,380
sino que no es lo mismo que la complejidad.

73
00:03:38,140 --> 00:03:43,960
Un agente podría tener un repertorio de acciones increíblemente rico y variado,

74
00:03:44,360 --> 00:03:45,860
y por tanto, ser muy complejo,

75
00:03:45,860 --> 00:03:51,860
incluso si su capacidad de añadir nuevas herramientas a su caja es cero.

76
00:03:51,860 --> 00:03:58,440
La complejidad es una foto del momento, no la película de su vida.

77
00:03:59,000 --> 00:04:01,560
Ok, ok. Acepto la premisa por ahora.

78
00:04:02,180 --> 00:04:07,420
Y si lo vemos así, podemos hacer comparaciones que antes eran, pues, impensables.

79
00:04:07,420 --> 00:04:13,380
Por ejemplo, pensemos en el caso de un insecto contra un robot industrial de alta tecnología.

80
00:04:13,960 --> 00:04:15,540
Es un ejemplo perfecto.

81
00:04:16,020 --> 00:04:20,020
El robot puede realizar cálculos internos complejísimos,

82
00:04:20,580 --> 00:04:23,840
una proeza de inteligencia computacional,

83
00:04:24,360 --> 00:04:27,180
pero quizás solo para hacer una única cosa,

84
00:04:27,680 --> 00:04:31,420
soldar una puerta de un carro con una precisión milimétrica.

85
00:04:31,740 --> 00:04:33,420
Y su repertorio de acciones es...

86
00:04:34,140 --> 00:04:34,640
minúsculo.

87
00:04:34,940 --> 00:04:35,540
Exacto.

88
00:04:35,540 --> 00:04:38,940
Mientras tanto, una hormiga, con un sistema nervioso

89
00:04:38,940 --> 00:04:42,040
que es una miniatura al lado del procesador del robot,

90
00:04:42,520 --> 00:04:45,420
tiene un abanico de posibilidades de acción brutal.

91
00:04:46,040 --> 00:04:48,280
Puede caminar, trepar, buscar comida,

92
00:04:48,700 --> 00:04:51,080
seguir rastros químicos, cargar objetos,

93
00:04:51,520 --> 00:04:53,620
comunicarse con otras hormigas...

94
00:04:53,620 --> 00:04:55,840
Construir parte de un hormiguero,

95
00:04:56,280 --> 00:04:58,000
luchar contra un enemigo...

96
00:04:58,000 --> 00:05:02,320
Si medimos la complejidad por la riqueza de ese espacio de actividad,

97
00:05:02,320 --> 00:05:05,300
la hormiga le gana por goleada al robot.

98
00:05:05,540 --> 00:05:08,940
Y ahí es donde la idea empieza a tomar forma.

99
00:05:09,840 --> 00:05:13,480
La complejidad no está en los gigaflops del procesador,

100
00:05:13,980 --> 00:05:16,960
sino en la riqueza de la interacción con el mundo.

101
00:05:17,940 --> 00:05:21,860
El robot es un genio encerrado en una jaula de una sola tarea.

102
00:05:22,620 --> 00:05:27,200
La hormiga es una maestra de la supervivencia en un mundo abierto y cambiante.

103
00:05:27,200 --> 00:05:34,100
Iber, espera un momento, porque aquí viene la parte que de verdad me parece que va en contra de todo lo que uno pensaría.

104
00:05:34,700 --> 00:05:41,300
El documento argumenta que las limitaciones, las restricciones, no son un enemigo de la complejidad.

105
00:05:41,660 --> 00:05:44,400
Al contrario, son las que la construyen.

106
00:05:45,100 --> 00:05:49,520
¿Me estás diciendo que tener menos opciones puede hacer que un sistema sea más complejo?

107
00:05:49,520 --> 00:05:50,820
¿Cómo es posible eso?

108
00:05:51,200 --> 00:05:52,560
Suena a paradoja, ¿verdad?

109
00:05:53,360 --> 00:05:57,660
Nuestra cultura nos dice que más libertad y más opciones siempre es mejor.

110
00:05:58,260 --> 00:05:59,700
Pero pensemos en un juego.

111
00:06:00,220 --> 00:06:03,840
¿Qué hace que el ajedrez sea un juego tan profundo y complejo?

112
00:06:04,220 --> 00:06:04,900
Sus reglas.

113
00:06:04,900 --> 00:06:06,220
Precisamente.

114
00:06:06,800 --> 00:06:08,360
Sus reglas, sus limitaciones.

115
00:06:09,000 --> 00:06:11,020
El alfil solo se puede mover en diagonal.

116
00:06:11,500 --> 00:06:12,800
El caballo solo en L.

117
00:06:13,420 --> 00:06:17,220
Si todas las piezas pudieran moverse a cualquier lado, no habría juego.

118
00:06:17,560 --> 00:06:18,260
Solo caos.

119
00:06:18,860 --> 00:06:19,940
No habría estrategia.

120
00:06:20,060 --> 00:06:21,180
No habría complejidad.

121
00:06:21,820 --> 00:06:23,160
Visto así, tiene sentido.

122
00:06:23,820 --> 00:06:27,140
Las reglas son las que crean el espacio para que surja la estrategia.

123
00:06:27,680 --> 00:06:29,260
Sin ellas, solo hay ruido.

124
00:06:29,900 --> 00:06:30,420
Justamente.

125
00:06:30,420 --> 00:06:36,780
Las limitaciones no solo restringen, sino que organizan.

126
00:06:37,880 --> 00:06:40,300
El artículo usa un ejemplo muy directo.

127
00:06:40,780 --> 00:06:42,300
Un ser humano bajo el agua.

128
00:06:43,120 --> 00:06:47,040
En ese entorno, la posibilidad de respirar desaparece.

129
00:06:47,700 --> 00:06:49,380
No es un defecto del humano.

130
00:06:50,020 --> 00:06:53,180
Es un desajuste entre la gente y su entorno.

131
00:06:53,760 --> 00:07:00,180
Esa ausencia de una acción posible estructura radicalmente todo lo que puede hacer a continuación.

132
00:07:01,420 --> 00:07:05,240
Su prioridad absoluta se convierte en buscar la superficie.

133
00:07:06,220 --> 00:07:09,740
La limitación le da un foco y una dirección a su comportamiento.

134
00:07:10,580 --> 00:07:12,720
Y supongo que esto también libera recursos.

135
00:07:13,440 --> 00:07:19,900
Si el entorno elimina de forma fiable ciertas posibilidades, no tienes que gastar energía ni tiempo en pensar en ellas.

136
00:07:19,900 --> 00:07:25,860
Por supuesto, un pez no delibera si debería intentar caminar por la playa.

137
00:07:26,580 --> 00:07:37,740
Esa imposibilidad es una restricción que simplifica su espacio de decisión y le permite ser increíblemente sofisticado en las cosas que sí puede hacer.

138
00:07:37,740 --> 00:07:41,500
Nadar, cazar, esconderse en el agua.

139
00:07:42,260 --> 00:07:45,160
Estas limitaciones economizan la acción.

140
00:07:45,800 --> 00:07:50,920
Permiten que muchas de nuestras actividades se vuelvan automáticas, fluidas.

141
00:07:50,920 --> 00:07:55,900
Liberando nuestra mente para ocuparnos de problemas de más alto nivel.

142
00:07:56,380 --> 00:07:56,980
Exacto.

143
00:07:57,120 --> 00:08:03,660
Es como si las restricciones construyeran los cimientos sólidos sobre los que podemos edificar comportamientos más elaborados.

144
00:08:04,100 --> 00:08:07,100
Son el andamiaje que permite construir el edificio.

145
00:08:07,380 --> 00:08:08,280
Ok, me convence.

146
00:08:08,280 --> 00:08:16,060
Entonces, si estas limitaciones organizan el espacio, ¿cómo se construyen las acciones más complejas a partir de las más simples?

147
00:08:16,460 --> 00:08:18,560
El texto habla de una jerarquía.

148
00:08:19,220 --> 00:08:24,420
Distingue entre posibilidades de acción, digamos básicas y compuestas.

149
00:08:25,080 --> 00:08:29,800
Una acción básica podría ser algo como agarrar un objeto.

150
00:08:30,420 --> 00:08:34,820
Es una acción directa que depende de la forma de tu mano y del objeto.

151
00:08:34,820 --> 00:08:40,140
Y una compuesta sería, por ejemplo, clavar un clavo con un martillo.

152
00:08:40,900 --> 00:08:42,660
Para eso no basta con agarrar.

153
00:08:43,100 --> 00:08:52,560
Necesitas agarrar el martillo, mover el brazo de una forma concreta, orientar la muñeca, apuntar, golpear con la fuerza justa.

154
00:08:52,980 --> 00:08:56,220
Es toda una secuencia coordinada de acciones básicas.

155
00:08:56,680 --> 00:08:58,620
Y aquí viene lo más interesante.

156
00:08:58,620 --> 00:09:14,440
Para que esa acción compuesta aparezca, no hace falta un director de orquesta en tu cerebro que esté calculando conscientemente cada milisegundo el ángulo del codo y la tensión de los músculos.

157
00:09:15,140 --> 00:09:18,460
Eso sería imposiblemente lento y costoso.

158
00:09:18,820 --> 00:09:19,220
Cierto.

159
00:09:19,640 --> 00:09:21,700
Cuando lo haces, simplemente lo haces.

160
00:09:21,980 --> 00:09:23,260
No piensas en los detalles.

161
00:09:23,260 --> 00:09:26,020
Porque el control se ha delegado.

162
00:09:26,420 --> 00:09:29,420
Pensemos en aprender a manejar un carro con cambios.

163
00:09:29,960 --> 00:09:32,520
Al principio es una pesadilla cognitiva.

164
00:09:33,260 --> 00:09:34,720
Piensas en cada paso.

165
00:09:35,360 --> 00:09:40,520
Piso el embrague, muevo la palanca, suelto el embrague suavemente, acelero un poquito.

166
00:09:41,240 --> 00:09:44,740
Pero después de meses de práctica, todo eso se comprime.

167
00:09:45,300 --> 00:09:47,140
Ya no piensas en los pies ni en la mano.

168
00:09:47,480 --> 00:09:51,720
Solo piensas en cambiar a tercera y tu cuerpo lo hace solo.

169
00:09:51,720 --> 00:09:55,240
El control de las acciones básicas se ha vuelto automático.

170
00:09:56,080 --> 00:09:58,180
Se ha relegado a un nivel inferior.

171
00:09:58,620 --> 00:09:59,220
Exacto.

172
00:09:59,560 --> 00:10:02,780
El artículo llama a eso relegación de control.

173
00:10:03,380 --> 00:10:04,720
El control no desaparece.

174
00:10:05,700 --> 00:10:10,200
Simplemente se automatiza y se traslada a circuitos de más bajo nivel.

175
00:10:11,000 --> 00:10:19,700
Esto libera tu atención para que te preocupes de cosas más importantes, como el tráfico, el peatón que va a cruzar o la ruta que debes seguir.

176
00:10:19,700 --> 00:10:29,940
La complejidad de conducir por la ciudad emerge porque los componentes básicos se volvieron tan fiables que ya no requieren tu supervisión constante.

177
00:10:30,440 --> 00:10:32,520
Te permite apilar complejidades.

178
00:10:32,960 --> 00:10:33,220
Ok.

179
00:10:33,220 --> 00:10:46,040
A ver, si aceptamos toda esta idea, que la complejidad se mide en el ahora, que las limitaciones la crean y que se construye delegando control, me surge un problema.

180
00:10:46,760 --> 00:10:56,400
Si ya no podemos usar la inteligencia como vara para medir todo, entonces, ¿cómo comparamos a una hormiga con un ser humano o a un pulpo con una ia?

181
00:10:56,400 --> 00:11:02,360
Se vuelve un todo vale donde ya no podemos decir que algo es más complejo que otra cosa.

182
00:11:02,600 --> 00:11:04,160
Es la pregunta del millón.

183
00:11:04,680 --> 00:11:08,820
Y la respuesta del artículo es, de nuevo, bastante radical.

184
00:11:09,580 --> 00:11:15,840
Nos dice que la mayoría de las veces la pregunta, ¿cuál es más complejo?, está mal formulada.

185
00:11:16,660 --> 00:11:25,760
Intentar poner a todos los seres en una única escalera lineal de menos a más complejo es precisamente la trampa de la que intentamos escapar.

186
00:11:25,760 --> 00:11:29,000
Entonces, ¿no hay ninguna forma de comparar?

187
00:11:29,720 --> 00:11:32,260
Sí la hay, pero no con un solo número.

188
00:11:32,920 --> 00:11:34,760
A veces la comparación es directa.

189
00:11:35,080 --> 00:11:44,160
Por ejemplo, un agente que puede caminar y correr es, sin duda, más complejo en su motricidad que un agente que solo puede caminar.

190
00:11:44,360 --> 00:11:54,160
Su repertorio de acciones incluye y expande el del otro, pero la mayoría de las veces las diferencias son cualitativas, no cuantitativas.

191
00:11:54,160 --> 00:11:57,340
¿Cómo comparar manzanas y naranjas?

192
00:11:58,340 --> 00:11:59,020
Exactamente.

193
00:11:59,560 --> 00:12:06,480
Un pulpo tiene una complejidad motriz alucinante, con ocho brazos que pueden moverse de forma independiente.

194
00:12:06,940 --> 00:12:13,720
Una abeja tiene una complejidad social increíble, con su danza para comunicar la ubicación de las flores.

195
00:12:14,180 --> 00:12:16,060
¿Cuál es más complejo?

196
00:12:16,480 --> 00:12:18,300
La pregunta no tiene sentido.

197
00:12:18,720 --> 00:12:23,020
Es como preguntar si un destornillador es mejor herramienta que un serrucho.

198
00:12:23,340 --> 00:12:24,440
Depende de para qué.

199
00:12:24,440 --> 00:12:30,380
El documento nos invita a aceptar que la complejidad es plural, es multidimensional.

200
00:12:30,840 --> 00:12:38,780
Y asumir esa incomparabilidad no es un fracaso del modelo, sino un reflejo honesto de la realidad.

201
00:12:39,280 --> 00:12:44,540
Es reconocer que la vida y la tecnología crean tipos de complejidad muy distintos.

202
00:12:44,540 --> 00:12:57,100
Forzar una clasificación única es reintroducir por la puerta de atrás la idea de que todo debe medirse en una escala que, casualmente, suele terminar con el ser humano en la cima.

203
00:12:57,100 --> 00:13:02,560
Esto me lleva a otro concepto que el artículo redefine, la robustez.

204
00:13:03,460 --> 00:13:12,020
Normalmente, pensamos que algo robusto es algo duro, que no se rompe, que ejecuta una tarea a la perfección una y otra vez.

205
00:13:12,500 --> 00:13:16,600
Como un martillo, que es robusto porque aguanta miles de golpes.

206
00:13:16,600 --> 00:13:19,900
Pero aquí, la robustez es algo muy diferente.

207
00:13:20,560 --> 00:13:23,220
No es rigidez, es flexibilidad.

208
00:13:24,280 --> 00:13:36,580
Un sistema robustamente complejo no es el que ejecuta una única función a la perfección, sino el que mantiene un espacio de acción diverso y viable cuando las cosas se tuercen o al entorno cambia.

209
00:13:37,120 --> 00:13:38,000
Dame un ejemplo.

210
00:13:38,000 --> 00:13:39,580
Pensemos en un cocinero.

211
00:13:39,960 --> 00:13:44,040
Un cocinero rígido es el que sigue una receta al pie de la letra.

212
00:13:44,360 --> 00:13:46,860
Si le falta un solo ingrediente, se bloquea.

213
00:13:47,080 --> 00:13:48,040
El sistema falla.

214
00:13:48,320 --> 00:14:01,360
Un cocinero robusto es el que se da cuenta de que no tiene perejil y, en lugar de entrar en pánico, lo sustituye por cilantro, ajusta un poco las especias e improvisa un plato nuevo y delicioso con lo que tiene a mano.

215
00:14:01,940 --> 00:14:03,120
Eso es robustez.

216
00:14:03,120 --> 00:14:07,320
La capacidad de reorganizar la acción para seguir funcionando.

217
00:14:07,320 --> 00:14:10,900
Es la capacidad de encontrar una solución alternativa.

218
00:14:11,680 --> 00:14:26,620
Entonces, un robot que al encontrar un obstáculo puede cambiar fluidamente entre caminar, trepar o rodearlo, es más robusto que uno que solo sabe caminar perfectamente en línea recta, pero se detiene en seco ante la primera piedra.

219
00:14:26,880 --> 00:14:27,760
Sin ninguna duda.

220
00:14:28,520 --> 00:14:34,360
Y por eso, los momentos de fallo, de breakdown, son tan reveladores.

221
00:14:34,360 --> 00:14:42,940
Cuando una acción falla, de repente se hace visible toda la estructura de dependencias que normalmente está oculta.

222
00:14:43,520 --> 00:14:49,760
Cuando el carro no arranca, de repente tienes que pensar en la batería, el motor de arranque, la gasolina.

223
00:14:50,480 --> 00:14:52,220
Cosas que dabas por sentadas.

224
00:14:52,220 --> 00:14:55,800
El fallo no es solo una pérdida de complejidad.

225
00:14:56,320 --> 00:15:01,120
Revela la profundidad de la organización que se necesita para mantenerla.

226
00:15:01,700 --> 00:15:02,100
Bien.

227
00:15:02,660 --> 00:15:04,800
Creo que el panorama está mucho más claro.

228
00:15:05,440 --> 00:15:10,060
Si tuviéramos que resumir el gran giro que nos propone este material, ¿cuál sería?

229
00:15:10,060 --> 00:15:24,540
El giro es dejar de obsesionarnos con lo que una gente piensa o lo que podría llegar a aprender y empezar a valorar la estructura organizada de lo que puede hacer aquí y ahora, en su acoplamiento único con su entorno.

230
00:15:25,040 --> 00:15:28,560
Es una visión de la complejidad anclada en la acción y en el presente.

231
00:15:28,560 --> 00:15:31,440
Resumiendo las ideas clave entonces.

232
00:15:32,520 --> 00:15:40,380
Primero, la complejidad es una foto del repertorio de acciones de este momento, no una película sobre su potencial.

233
00:15:41,020 --> 00:15:44,980
Segundo, las limitaciones no son un error.

234
00:15:45,680 --> 00:15:49,800
Son el andamiaje que da forma y coherencia a la acción,

235
00:15:50,780 --> 00:15:57,500
permitiendo que surjan comportamientos sofisticados a partir de reglas simples, como en el ajedrez.

236
00:15:57,500 --> 00:16:03,160
Y tercero, y quizás lo más importante, la complejidad tiene muchas caras.

237
00:16:03,920 --> 00:16:04,380
Es plural.

238
00:16:05,300 --> 00:16:17,840
Por lo tanto, intentar meter todo en una misma clasificación de más o menos complejo, no solo es difícil, sino que a menudo es inútil y nos impide ver la riqueza que hay en la diversidad.

239
00:16:17,840 --> 00:16:19,440
Has dado en el clavo.

240
00:16:20,040 --> 00:16:29,140
Es un llamado a apreciar las distintas formas de ser complejo, sin buscar siempre una única escalera que nos lleve a nosotros, como el escalón final.

241
00:16:29,300 --> 00:16:31,980
Al final, me quedo con una pregunta que da vueltas.

242
00:16:32,320 --> 00:16:34,480
Una idea que se desprende de todo esto.

243
00:16:34,480 --> 00:16:44,100
Si se puede tener una complejidad rica, robusta y adaptable, sin necesidad de una inteligencia como la entendemos, sin grandes cerebros deliberando,

244
00:16:44,580 --> 00:16:48,620
¿qué nos dice eso sobre la forma en que estamos buscando crear inteligencia artificial?

245
00:16:49,040 --> 00:16:56,320
Es una pregunta muy provocadora, porque es cierto que gran parte del esfuerzo se ha centrado en el software,

246
00:16:56,600 --> 00:17:03,100
en crear algoritmos de razonamiento cada vez más potentes, en imitar el pensamiento humano abstracto.

247
00:17:03,100 --> 00:17:04,880
¿Y si el objetivo cambiara?

248
00:17:05,300 --> 00:17:08,960
¿Y si dejáramos de intentar construir cerebros gigantes en una caja?

249
00:17:09,420 --> 00:17:15,120
¿Cómo serían nuestros robots y sistemas autónomos si la meta no fuera la inteligencia deliberativa,

250
00:17:15,600 --> 00:17:21,740
sino crear agentes con una complejidad de acción rica y flexible, capaces de bailar con el mundo real?

251
00:17:22,580 --> 00:17:26,920
Me da la sensación de que, quizás, hemos estado buscando en el lugar equivocado.

